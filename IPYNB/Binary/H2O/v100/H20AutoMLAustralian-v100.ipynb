{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tk34b2C7bI-i",
    "outputId": "9866df90-d4c6-4c6c-e88e-39b1d441345a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting h2o\n",
      "  Downloading h2o-3.36.1.1.tar.gz (177.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 177.0 MB 131.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from h2o) (2.24.0)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 91.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->h2o) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->h2o) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->h2o) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->h2o) (2020.6.20)\n",
      "Building wheels for collected packages: h2o, future\n",
      "  Building wheel for h2o (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for h2o: filename=h2o-3.36.1.1-py2.py3-none-any.whl size=177068062 sha256=0533030546660b1c148809ab4577dcff647b0b881df5f2d4b3bf02c973cf12d2\n",
      "  Stored in directory: /home/mk7516/.cache/pip/wheels/bf/d7/e0/905f059465fafaf07c9e79ba4c8d642ac646b01ea8c38b07d5\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=4f831c65e1c94dc6bcb6bd66006a00f5a1ba67ae0b30925cbe353bfd64aac98a\n",
      "  Stored in directory: /home/mk7516/.cache/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built h2o future\n",
      "Installing collected packages: tabulate, future, h2o\n",
      "Successfully installed future-0.18.2 h2o-3.36.1.1 tabulate-0.8.9\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kCgyhMjHJB6Y"
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "cNn--_UnbWd-",
    "outputId": "274afb96-bd18-492e-e8a6-5be73eb680d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_312-debug\"; OpenJDK Runtime Environment (build 1.8.0_312-debug-b07); OpenJDK 64-Bit Server VM (build 25.312-b07-debug, mixed mode)\n",
      "  Starting server from /home/mk7516/.local/lib/python3.8/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /state/partition1/job-19156485/tmpm67nwqaf\n",
      "  JVM stdout: /state/partition1/job-19156485/tmpm67nwqaf/h2o_mk7516_started_from_python.out\n",
      "  JVM stderr: /state/partition1/job-19156485/tmpm67nwqaf/h2o_mk7516_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>07 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.36.1.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>22 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_mk7516_u150lq</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.541 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         07 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.36.1.1\n",
       "H2O_cluster_version_age:    22 days\n",
       "H2O_cluster_name:           H2O_from_python_mk7516_u150lq\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.541 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.6 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kdt8Wp7Falm7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def dataSetup(name):\n",
    "  X,y = sklearn.datasets.fetch_openml(name, as_frame=True, return_X_y=True)\n",
    "  train = pd.concat([X, y], axis=1, join='inner')\n",
    "  train.dropna()\n",
    "  train = train.apply(lambda x: pd.factorize(x)[0])\n",
    "  X,y = train.iloc[:,:-1], train.iloc[:, -1]\n",
    "  # X = X.apply(lambda x: pd.factorize(x)[0])\n",
    "  X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y,random_state=42)\n",
    "  y_train = y_train.to_frame(name=\"class\")\n",
    "  y_test = y_test.to_frame(name=\"class\")\n",
    "  test = pd.concat([X_test, y_test], axis=1, join='inner')\n",
    "  train = pd.concat([X_train, y_train], axis=1, join='inner')\n",
    "  test = h2o.H2OFrame(test)\n",
    "  train = h2o.H2OFrame(train)\n",
    "  return (test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gpw9R9koa8kA",
    "outputId": "3d5374f5-b7db-46ec-c5cb-7fc10df849a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "test, train = dataSetup('australian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0LPdFQlbA_5",
    "outputId": "d582af48-65ba-4760-e90b-e936af7442f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uDeYZ8nTQX-0"
   },
   "outputs": [],
   "source": [
    "x = train.columns\n",
    "y = \"class\"\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "u_ErSp1nU27w"
   },
   "outputs": [],
   "source": [
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1J4XoxvQunQ",
    "outputId": "f116c4e2-0059-4307-f9a4-1c3892867859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_1_AutoML_1_20220506_142744_model_95\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21740.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.818182</td>\n",
       "      <td>30.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>47.575756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               33.0                      33.0              21740.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        8.0       12.0   10.818182        30.0        52.0    47.575756  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.022022418832576832\n",
      "RMSE: 0.1483995243677581\n",
      "LogLoss: 0.11082597111600354\n",
      "Mean Per-Class Error: 0.01788291538877864\n",
      "AUC: 0.9988874857177221\n",
      "AUCPR: 0.9987567961287924\n",
      "Gini: 0.9977749714354442\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4801280789764455: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>(3.0/276.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>(6.0/241.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>279.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>(9.0/517.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1   Error          Rate\n",
       "0      0  273.0    3.0  0.0109   (3.0/276.0)\n",
       "1      1    6.0  235.0  0.0249   (6.0/241.0)\n",
       "2  Total  279.0  238.0  0.0174   (9.0/517.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.480128</td>\n",
       "      <td>0.981211</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.376570</td>\n",
       "      <td>0.990140</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.607812</td>\n",
       "      <td>0.990525</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.480128</td>\n",
       "      <td>0.982592</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.981153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.376570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.981153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.480128</td>\n",
       "      <td>0.965062</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.450836</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.480128</td>\n",
       "      <td>0.982117</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.981153</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.981153</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.376570</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.981153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.981153</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.376570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold       value    idx\n",
       "0                        max f1   0.480128    0.981211  187.0\n",
       "1                        max f2   0.376570    0.990140  202.0\n",
       "2                  max f0point5   0.607812    0.990525  179.0\n",
       "3                  max accuracy   0.480128    0.982592  187.0\n",
       "4                 max precision   0.981153    1.000000    0.0\n",
       "5                    max recall   0.376570    1.000000  202.0\n",
       "6               max specificity   0.981153    1.000000    0.0\n",
       "7              max absolute_mcc   0.480128    0.965062  187.0\n",
       "8    max min_per_class_accuracy   0.450836    0.978261  191.0\n",
       "9   max mean_per_class_accuracy   0.480128    0.982117  187.0\n",
       "10                      max tns   0.981153  276.000000    0.0\n",
       "11                      max fns   0.981153  240.000000    0.0\n",
       "12                      max fps   0.015043  276.000000  399.0\n",
       "13                      max tps   0.376570  241.000000  202.0\n",
       "14                      max tnr   0.981153    1.000000    0.0\n",
       "15                      max fnr   0.981153    0.995851    0.0\n",
       "16                      max fpr   0.015043    1.000000  399.0\n",
       "17                      max tpr   0.376570    1.000000  202.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 46.62 %, avg score: 46.90 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.978203</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979323</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.024896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.976927</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978477</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.045643</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.045643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030948</td>\n",
       "      <td>0.974283</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977563</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.066390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.973789</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976715</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.087137</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.087137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050290</td>\n",
       "      <td>0.972437</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976038</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.107884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100580</td>\n",
       "      <td>0.966444</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972800</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.215768</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.215768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150870</td>\n",
       "      <td>0.958994</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969457</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.323651</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.323651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.201161</td>\n",
       "      <td>0.951170</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965853</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.431535</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.431535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.299807</td>\n",
       "      <td>0.931743</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957978</td>\n",
       "      <td>0.211618</td>\n",
       "      <td>0.643154</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.643154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400387</td>\n",
       "      <td>0.831656</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.215768</td>\n",
       "      <td>0.858921</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.858921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500967</td>\n",
       "      <td>0.336987</td>\n",
       "      <td>1.402649</td>\n",
       "      <td>1.996139</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.573020</td>\n",
       "      <td>0.930502</td>\n",
       "      <td>0.867748</td>\n",
       "      <td>0.141079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.264922</td>\n",
       "      <td>99.613900</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.599613</td>\n",
       "      <td>0.093330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.667742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169626</td>\n",
       "      <td>0.777419</td>\n",
       "      <td>0.752895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>66.774194</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700193</td>\n",
       "      <td>0.055577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072330</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.655135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>42.817680</td>\n",
       "      <td>0.561594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.798839</td>\n",
       "      <td>0.039326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.251816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046947</td>\n",
       "      <td>0.583535</td>\n",
       "      <td>0.580032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.181598</td>\n",
       "      <td>0.376812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899420</td>\n",
       "      <td>0.027454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032954</td>\n",
       "      <td>0.518280</td>\n",
       "      <td>0.518853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.182796</td>\n",
       "      <td>0.188406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022719</td>\n",
       "      <td>0.466151</td>\n",
       "      <td>0.468952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.011605         0.978203  2.145228   \n",
       "1       2                  0.021277         0.976927  2.145228   \n",
       "2       3                  0.030948         0.974283  2.145228   \n",
       "3       4                  0.040619         0.973789  2.145228   \n",
       "4       5                  0.050290         0.972437  2.145228   \n",
       "5       6                  0.100580         0.966444  2.145228   \n",
       "6       7                  0.150870         0.958994  2.145228   \n",
       "7       8                  0.201161         0.951170  2.145228   \n",
       "8       9                  0.299807         0.931743  2.145228   \n",
       "9      10                  0.400387         0.831656  2.145228   \n",
       "10     11                  0.500967         0.336987  1.402649   \n",
       "11     12                  0.599613         0.093330  0.000000   \n",
       "12     13                  0.700193         0.055577  0.000000   \n",
       "13     14                  0.798839         0.039326  0.000000   \n",
       "14     15                  0.899420         0.027454  0.000000   \n",
       "15     16                  1.000000         0.015043  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          2.145228       1.000000  0.979323                  1.000000   \n",
       "1          2.145228       1.000000  0.977462                  1.000000   \n",
       "2          2.145228       1.000000  0.975553                  1.000000   \n",
       "3          2.145228       1.000000  0.974000                  1.000000   \n",
       "4          2.145228       1.000000  0.973197                  1.000000   \n",
       "5          2.145228       1.000000  0.969562                  1.000000   \n",
       "6          2.145228       1.000000  0.962770                  1.000000   \n",
       "7          2.145228       1.000000  0.955040                  1.000000   \n",
       "8          2.145228       1.000000  0.941919                  1.000000   \n",
       "9          2.145228       1.000000  0.893520                  1.000000   \n",
       "10         1.996139       0.653846  0.573020                  0.930502   \n",
       "11         1.667742       0.000000  0.169626                  0.777419   \n",
       "12         1.428177       0.000000  0.072330                  0.665746   \n",
       "13         1.251816       0.000000  0.046947                  0.583535   \n",
       "14         1.111828       0.000000  0.032954                  0.518280   \n",
       "15         1.000000       0.000000  0.022719                  0.466151   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.979323      0.024896                 0.024896  114.522822   \n",
       "1           0.978477      0.020747                 0.045643  114.522822   \n",
       "2           0.977563      0.020747                 0.066390  114.522822   \n",
       "3           0.976715      0.020747                 0.087137  114.522822   \n",
       "4           0.976038      0.020747                 0.107884  114.522822   \n",
       "5           0.972800      0.107884                 0.215768  114.522822   \n",
       "6           0.969457      0.107884                 0.323651  114.522822   \n",
       "7           0.965853      0.107884                 0.431535  114.522822   \n",
       "8           0.957978      0.211618                 0.643154  114.522822   \n",
       "9           0.941785      0.215768                 0.858921  114.522822   \n",
       "10          0.867748      0.141079                 1.000000   40.264922   \n",
       "11          0.752895      0.000000                 1.000000 -100.000000   \n",
       "12          0.655135      0.000000                 1.000000 -100.000000   \n",
       "13          0.580032      0.000000                 1.000000 -100.000000   \n",
       "14          0.518853      0.000000                 1.000000 -100.000000   \n",
       "15          0.468952      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        114.522822            0.024896  \n",
       "1        114.522822            0.045643  \n",
       "2        114.522822            0.066390  \n",
       "3        114.522822            0.087137  \n",
       "4        114.522822            0.107884  \n",
       "5        114.522822            0.215768  \n",
       "6        114.522822            0.323651  \n",
       "7        114.522822            0.431535  \n",
       "8        114.522822            0.643154  \n",
       "9        114.522822            0.858921  \n",
       "10        99.613900            0.934783  \n",
       "11        66.774194            0.750000  \n",
       "12        42.817680            0.561594  \n",
       "13        25.181598            0.376812  \n",
       "14        11.182796            0.188406  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.09663573633845675\n",
      "RMSE: 0.31086288993454453\n",
      "LogLoss: 0.32776752023274763\n",
      "Mean Per-Class Error: 0.1210009621745144\n",
      "AUC: 0.933053701365085\n",
      "AUCPR: 0.9359814583034342\n",
      "Gini: 0.8661074027301701\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6335835722431616: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>(29.0/276.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>(33.0/241.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>280.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>(62.0/517.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1   Error           Rate\n",
       "0      0  247.0   29.0  0.1051   (29.0/276.0)\n",
       "1      1   33.0  208.0  0.1369   (33.0/241.0)\n",
       "2  Total  280.0  237.0  0.1199   (62.0/517.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.633584</td>\n",
       "      <td>0.870293</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.189587</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.765465</td>\n",
       "      <td>0.894009</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.652074</td>\n",
       "      <td>0.880077</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.652074</td>\n",
       "      <td>0.758911</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.606308</td>\n",
       "      <td>0.875519</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.633584</td>\n",
       "      <td>0.878999</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold       value    idx\n",
       "0                        max f1   0.633584    0.870293  185.0\n",
       "1                        max f2   0.189587    0.899281  232.0\n",
       "2                  max f0point5   0.765465    0.894009  161.0\n",
       "3                  max accuracy   0.652074    0.880077  182.0\n",
       "4                 max precision   0.990096    1.000000    0.0\n",
       "5                    max recall   0.008875    1.000000  398.0\n",
       "6               max specificity   0.990096    1.000000    0.0\n",
       "7              max absolute_mcc   0.652074    0.758911  182.0\n",
       "8    max min_per_class_accuracy   0.606308    0.875519  191.0\n",
       "9   max mean_per_class_accuracy   0.633584    0.878999  185.0\n",
       "10                      max tns   0.990096  276.000000    0.0\n",
       "11                      max fns   0.990096  240.000000    0.0\n",
       "12                      max fps   0.008365  276.000000  399.0\n",
       "13                      max tps   0.008875  241.000000  398.0\n",
       "14                      max tnr   0.990096    1.000000    0.0\n",
       "15                      max fnr   0.990096    0.995851    0.0\n",
       "16                      max fpr   0.008365    1.000000  399.0\n",
       "17                      max tpr   0.008875    1.000000  398.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 46.62 %, avg score: 47.53 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.977787</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981772</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.024896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.976040</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979467</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.045643</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.045643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030948</td>\n",
       "      <td>0.973295</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977980</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.066390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.971577</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976619</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.087137</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.087137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050290</td>\n",
       "      <td>0.966800</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975268</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.107884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100580</td>\n",
       "      <td>0.953588</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967715</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.215768</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>0.215768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150870</td>\n",
       "      <td>0.944090</td>\n",
       "      <td>2.062719</td>\n",
       "      <td>2.117725</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.948675</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.961368</td>\n",
       "      <td>0.103734</td>\n",
       "      <td>0.319502</td>\n",
       "      <td>106.271944</td>\n",
       "      <td>111.772529</td>\n",
       "      <td>0.315879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.201161</td>\n",
       "      <td>0.932480</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>2.124601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939306</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.955852</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.427386</td>\n",
       "      <td>114.522822</td>\n",
       "      <td>112.460102</td>\n",
       "      <td>0.423763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.299807</td>\n",
       "      <td>0.888049</td>\n",
       "      <td>1.892848</td>\n",
       "      <td>2.048347</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.942278</td>\n",
       "      <td>0.186722</td>\n",
       "      <td>0.614108</td>\n",
       "      <td>89.284843</td>\n",
       "      <td>104.834694</td>\n",
       "      <td>0.588746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400387</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>1.773939</td>\n",
       "      <td>1.979413</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.843848</td>\n",
       "      <td>0.922705</td>\n",
       "      <td>0.917552</td>\n",
       "      <td>0.178423</td>\n",
       "      <td>0.792531</td>\n",
       "      <td>77.393872</td>\n",
       "      <td>97.941347</td>\n",
       "      <td>0.734560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500967</td>\n",
       "      <td>0.402692</td>\n",
       "      <td>1.031360</td>\n",
       "      <td>1.789071</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.641446</td>\n",
       "      <td>0.833977</td>\n",
       "      <td>0.862117</td>\n",
       "      <td>0.103734</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>3.135972</td>\n",
       "      <td>78.907064</td>\n",
       "      <td>0.740468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.599613</td>\n",
       "      <td>0.127731</td>\n",
       "      <td>0.462696</td>\n",
       "      <td>1.570861</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.219484</td>\n",
       "      <td>0.732258</td>\n",
       "      <td>0.756394</td>\n",
       "      <td>0.045643</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>-53.730372</td>\n",
       "      <td>57.086066</td>\n",
       "      <td>0.641184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700193</td>\n",
       "      <td>0.073730</td>\n",
       "      <td>0.206272</td>\n",
       "      <td>1.374842</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.096196</td>\n",
       "      <td>0.640884</td>\n",
       "      <td>0.661559</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.962656</td>\n",
       "      <td>-79.372806</td>\n",
       "      <td>37.484239</td>\n",
       "      <td>0.491641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.798839</td>\n",
       "      <td>0.050298</td>\n",
       "      <td>0.126190</td>\n",
       "      <td>1.220650</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.060805</td>\n",
       "      <td>0.569007</td>\n",
       "      <td>0.587374</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>0.975104</td>\n",
       "      <td>-87.381010</td>\n",
       "      <td>22.065044</td>\n",
       "      <td>0.330176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899420</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.082509</td>\n",
       "      <td>1.093374</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.039484</td>\n",
       "      <td>0.509677</td>\n",
       "      <td>0.526104</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.983402</td>\n",
       "      <td>-91.749122</td>\n",
       "      <td>9.337438</td>\n",
       "      <td>0.157316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.165018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.466151</td>\n",
       "      <td>0.475340</td>\n",
       "      <td>0.016598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-83.498244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.011605         0.977787  2.145228   \n",
       "1       2                  0.021277         0.976040  2.145228   \n",
       "2       3                  0.030948         0.973295  2.145228   \n",
       "3       4                  0.040619         0.971577  2.145228   \n",
       "4       5                  0.050290         0.966800  2.145228   \n",
       "5       6                  0.100580         0.953588  2.145228   \n",
       "6       7                  0.150870         0.944090  2.062719   \n",
       "7       8                  0.201161         0.932480  2.145228   \n",
       "8       9                  0.299807         0.888049  1.892848   \n",
       "9      10                  0.400387         0.786408  1.773939   \n",
       "10     11                  0.500967         0.402692  1.031360   \n",
       "11     12                  0.599613         0.127731  0.462696   \n",
       "12     13                  0.700193         0.073730  0.206272   \n",
       "13     14                  0.798839         0.050298  0.126190   \n",
       "14     15                  0.899420         0.030673  0.082509   \n",
       "15     16                  1.000000         0.008365  0.165018   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          2.145228       1.000000  0.981772                  1.000000   \n",
       "1          2.145228       1.000000  0.976700                  1.000000   \n",
       "2          2.145228       1.000000  0.974710                  1.000000   \n",
       "3          2.145228       1.000000  0.972264                  1.000000   \n",
       "4          2.145228       1.000000  0.969593                  1.000000   \n",
       "5          2.145228       1.000000  0.960162                  1.000000   \n",
       "6          2.117725       0.961538  0.948675                  0.987179   \n",
       "7          2.124601       1.000000  0.939306                  0.990385   \n",
       "8          2.048347       0.882353  0.914597                  0.954839   \n",
       "9          1.979413       0.826923  0.843848                  0.922705   \n",
       "10         1.789071       0.480769  0.641446                  0.833977   \n",
       "11         1.570861       0.215686  0.219484                  0.732258   \n",
       "12         1.374842       0.096154  0.096196                  0.640884   \n",
       "13         1.220650       0.058824  0.060805                  0.569007   \n",
       "14         1.093374       0.038462  0.039484                  0.509677   \n",
       "15         1.000000       0.076923  0.021390                  0.466151   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.981772      0.024896                 0.024896  114.522822   \n",
       "1           0.979467      0.020747                 0.045643  114.522822   \n",
       "2           0.977980      0.020747                 0.066390  114.522822   \n",
       "3           0.976619      0.020747                 0.087137  114.522822   \n",
       "4           0.975268      0.020747                 0.107884  114.522822   \n",
       "5           0.967715      0.107884                 0.215768  114.522822   \n",
       "6           0.961368      0.103734                 0.319502  106.271944   \n",
       "7           0.955852      0.107884                 0.427386  114.522822   \n",
       "8           0.942278      0.186722                 0.614108   89.284843   \n",
       "9           0.917552      0.178423                 0.792531   77.393872   \n",
       "10          0.862117      0.103734                 0.896266    3.135972   \n",
       "11          0.756394      0.045643                 0.941909  -53.730372   \n",
       "12          0.661559      0.020747                 0.962656  -79.372806   \n",
       "13          0.587374      0.012448                 0.975104  -87.381010   \n",
       "14          0.526104      0.008299                 0.983402  -91.749122   \n",
       "15          0.475340      0.016598                 1.000000  -83.498244   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        114.522822            0.024896  \n",
       "1        114.522822            0.045643  \n",
       "2        114.522822            0.066390  \n",
       "3        114.522822            0.087137  \n",
       "4        114.522822            0.107884  \n",
       "5        114.522822            0.215768  \n",
       "6        111.772529            0.315879  \n",
       "7        112.460102            0.423763  \n",
       "8        104.834694            0.588746  \n",
       "9         97.941347            0.734560  \n",
       "10        78.907064            0.740468  \n",
       "11        57.086066            0.641184  \n",
       "12        37.484239            0.491641  \n",
       "13        22.065044            0.330176  \n",
       "14         9.337438            0.157316  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.887771</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>0.894231</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.893204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.929229</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>0.939259</td>\n",
       "      <td>0.935257</td>\n",
       "      <td>0.912644</td>\n",
       "      <td>0.932946</td>\n",
       "      <td>0.926038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>err</td>\n",
       "      <td>0.112229</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>0.105769</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.106796</td>\n",
       "      <td>0.106796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err_count</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>1.949359</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f0point5</td>\n",
       "      <td>0.880160</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.933610</td>\n",
       "      <td>0.810277</td>\n",
       "      <td>0.876777</td>\n",
       "      <td>0.894309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.879185</td>\n",
       "      <td>0.021720</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f2</td>\n",
       "      <td>0.879356</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>0.896414</td>\n",
       "      <td>0.868726</td>\n",
       "      <td>0.883621</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.883534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lift_top_group</td>\n",
       "      <td>2.157300</td>\n",
       "      <td>0.178511</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>1.962264</td>\n",
       "      <td>2.288889</td>\n",
       "      <td>2.395349</td>\n",
       "      <td>2.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.339233</td>\n",
       "      <td>0.034391</td>\n",
       "      <td>0.310588</td>\n",
       "      <td>0.330498</td>\n",
       "      <td>0.398424</td>\n",
       "      <td>0.335133</td>\n",
       "      <td>0.321521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.142249</td>\n",
       "      <td>0.030801</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.776749</td>\n",
       "      <td>0.036432</td>\n",
       "      <td>0.788451</td>\n",
       "      <td>0.813460</td>\n",
       "      <td>0.715720</td>\n",
       "      <td>0.779857</td>\n",
       "      <td>0.786254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.888298</td>\n",
       "      <td>0.016544</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.904920</td>\n",
       "      <td>0.860728</td>\n",
       "      <td>0.888566</td>\n",
       "      <td>0.892830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.111702</td>\n",
       "      <td>0.016544</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.095080</td>\n",
       "      <td>0.139272</td>\n",
       "      <td>0.111434</td>\n",
       "      <td>0.107170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.098513</td>\n",
       "      <td>0.015338</td>\n",
       "      <td>0.089395</td>\n",
       "      <td>0.087994</td>\n",
       "      <td>0.124368</td>\n",
       "      <td>0.100852</td>\n",
       "      <td>0.089957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pr_auc</td>\n",
       "      <td>0.928827</td>\n",
       "      <td>0.028714</td>\n",
       "      <td>0.944040</td>\n",
       "      <td>0.958047</td>\n",
       "      <td>0.883164</td>\n",
       "      <td>0.937406</td>\n",
       "      <td>0.921480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.881435</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.601883</td>\n",
       "      <td>0.065139</td>\n",
       "      <td>0.641890</td>\n",
       "      <td>0.647893</td>\n",
       "      <td>0.494474</td>\n",
       "      <td>0.585293</td>\n",
       "      <td>0.639867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.880127</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.313158</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>0.298990</td>\n",
       "      <td>0.296638</td>\n",
       "      <td>0.352659</td>\n",
       "      <td>0.317573</td>\n",
       "      <td>0.299928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>specificity</td>\n",
       "      <td>0.896469</td>\n",
       "      <td>0.055008</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.905660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  mean        sd  cv_1_valid  cv_2_valid  \\\n",
       "0                  accuracy   0.887771  0.019202    0.894231    0.903846   \n",
       "1                       auc   0.929229  0.010440    0.939259    0.935257   \n",
       "2                       err   0.112229  0.019202    0.105769    0.096154   \n",
       "3                 err_count  11.600000  1.949359   11.000000   10.000000   \n",
       "4                  f0point5   0.880160  0.044678    0.885827    0.933610   \n",
       "5                        f1   0.879185  0.021720    0.891089    0.900000   \n",
       "6                        f2   0.879356  0.012853    0.896414    0.868726   \n",
       "7            lift_top_group   2.157300  0.178511    2.080000    1.962264   \n",
       "8                   logloss   0.339233  0.034391    0.310588    0.330498   \n",
       "9       max_per_class_error   0.142249  0.030801    0.111111    0.150943   \n",
       "10                      mcc   0.776749  0.036432    0.788451    0.813460   \n",
       "11  mean_per_class_accuracy   0.888298  0.016544    0.894444    0.904920   \n",
       "12     mean_per_class_error   0.111702  0.016544    0.105556    0.095080   \n",
       "13                      mse   0.098513  0.015338    0.089395    0.087994   \n",
       "14                   pr_auc   0.928827  0.028714    0.944040    0.958047   \n",
       "15                precision   0.881435  0.060613    0.882353    0.957447   \n",
       "16                       r2   0.601883  0.065139    0.641890    0.647893   \n",
       "17                   recall   0.880127  0.026014    0.900000    0.849057   \n",
       "18                     rmse   0.313158  0.023603    0.298990    0.296638   \n",
       "19              specificity   0.896469  0.055008    0.888889    0.960784   \n",
       "\n",
       "    cv_3_valid  cv_4_valid  cv_5_valid  \n",
       "0     0.854369    0.893204    0.893204  \n",
       "1     0.912644    0.932946    0.926038  \n",
       "2     0.145631    0.106796    0.106796  \n",
       "3    15.000000   11.000000   11.000000  \n",
       "4     0.810277    0.876777    0.894309  \n",
       "5     0.845361    0.870588    0.888889  \n",
       "6     0.883621    0.864486    0.883534  \n",
       "7     2.288889    2.395349    2.060000  \n",
       "8     0.398424    0.335133    0.321521  \n",
       "9     0.189655    0.139535    0.120000  \n",
       "10    0.715720    0.779857    0.786254  \n",
       "11    0.860728    0.888566    0.892830  \n",
       "12    0.139272    0.111434    0.107170  \n",
       "13    0.124368    0.100852    0.089957  \n",
       "14    0.883164    0.937406    0.921480  \n",
       "15    0.788462    0.880952    0.897959  \n",
       "16    0.494474    0.585293    0.639867  \n",
       "17    0.911111    0.860465    0.880000  \n",
       "18    0.352659    0.317573    0.299928  \n",
       "19    0.810345    0.916667    0.905660  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2022-05-06 15:25:08</td>\n",
       "      <td>52.004 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498853</td>\n",
       "      <td>0.690854</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2022-05-06 15:25:08</td>\n",
       "      <td>52.022 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.364060</td>\n",
       "      <td>0.447664</td>\n",
       "      <td>0.980847</td>\n",
       "      <td>0.980752</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>0.069632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2022-05-06 15:25:08</td>\n",
       "      <td>52.042 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.289620</td>\n",
       "      <td>0.324527</td>\n",
       "      <td>0.986086</td>\n",
       "      <td>0.985582</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>0.059961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2022-05-06 15:25:08</td>\n",
       "      <td>52.062 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.242392</td>\n",
       "      <td>0.247383</td>\n",
       "      <td>0.990574</td>\n",
       "      <td>0.990459</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>0.044487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2022-05-06 15:25:08</td>\n",
       "      <td>52.081 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.211633</td>\n",
       "      <td>0.197082</td>\n",
       "      <td>0.993114</td>\n",
       "      <td>0.992948</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>0.032882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2022-05-06 15:25:08</td>\n",
       "      <td>52.102 sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.186880</td>\n",
       "      <td>0.158626</td>\n",
       "      <td>0.995866</td>\n",
       "      <td>0.995568</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>0.032882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2022-05-06 15:25:08</td>\n",
       "      <td>52.121 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.163603</td>\n",
       "      <td>0.127328</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>0.997489</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>0.023211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2022-05-06 15:25:08</td>\n",
       "      <td>52.135 sec</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.110826</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>2.145228</td>\n",
       "      <td>0.017408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0    2022-05-06 15:25:08  52.004 sec              0.0       0.498853   \n",
       "1    2022-05-06 15:25:08  52.022 sec              5.0       0.364060   \n",
       "2    2022-05-06 15:25:08  52.042 sec             10.0       0.289620   \n",
       "3    2022-05-06 15:25:08  52.062 sec             15.0       0.242392   \n",
       "4    2022-05-06 15:25:08  52.081 sec             20.0       0.211633   \n",
       "5    2022-05-06 15:25:08  52.102 sec             25.0       0.186880   \n",
       "6    2022-05-06 15:25:08  52.121 sec             30.0       0.163603   \n",
       "7    2022-05-06 15:25:08  52.135 sec             33.0       0.148400   \n",
       "\n",
       "   training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0          0.690854      0.500000         0.466151       1.000000   \n",
       "1          0.447664      0.980847         0.980752       2.145228   \n",
       "2          0.324527      0.986086         0.985582       2.145228   \n",
       "3          0.247383      0.990574         0.990459       2.145228   \n",
       "4          0.197082      0.993114         0.992948       2.145228   \n",
       "5          0.158626      0.995866         0.995568       2.145228   \n",
       "6          0.127328      0.997700         0.997489       2.145228   \n",
       "7          0.110826      0.998887         0.998757       2.145228   \n",
       "\n",
       "   training_classification_error  \n",
       "0                       0.533849  \n",
       "1                       0.069632  \n",
       "2                       0.059961  \n",
       "3                       0.044487  \n",
       "4                       0.032882  \n",
       "5                       0.032882  \n",
       "6                       0.023211  \n",
       "7                       0.017408  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A8</td>\n",
       "      <td>266.960815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A9</td>\n",
       "      <td>70.785393</td>\n",
       "      <td>0.265153</td>\n",
       "      <td>0.121603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>54.938286</td>\n",
       "      <td>0.205792</td>\n",
       "      <td>0.094379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3</td>\n",
       "      <td>37.117981</td>\n",
       "      <td>0.139039</td>\n",
       "      <td>0.063765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A13</td>\n",
       "      <td>34.818306</td>\n",
       "      <td>0.130425</td>\n",
       "      <td>0.059815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A7</td>\n",
       "      <td>26.069323</td>\n",
       "      <td>0.097652</td>\n",
       "      <td>0.044785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A5</td>\n",
       "      <td>25.925480</td>\n",
       "      <td>0.097113</td>\n",
       "      <td>0.044538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A14</td>\n",
       "      <td>17.399439</td>\n",
       "      <td>0.065176</td>\n",
       "      <td>0.029891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A10</td>\n",
       "      <td>17.305044</td>\n",
       "      <td>0.064822</td>\n",
       "      <td>0.029728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A12</td>\n",
       "      <td>8.257612</td>\n",
       "      <td>0.030932</td>\n",
       "      <td>0.014186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A6</td>\n",
       "      <td>7.105100</td>\n",
       "      <td>0.026615</td>\n",
       "      <td>0.012206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A4</td>\n",
       "      <td>6.118043</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>0.010510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A11</td>\n",
       "      <td>4.930174</td>\n",
       "      <td>0.018468</td>\n",
       "      <td>0.008470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A1</td>\n",
       "      <td>4.372194</td>\n",
       "      <td>0.016378</td>\n",
       "      <td>0.007511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable  relative_importance  scaled_importance  percentage\n",
       "0        A8           266.960815           1.000000    0.458614\n",
       "1        A9            70.785393           0.265153    0.121603\n",
       "2        A2            54.938286           0.205792    0.094379\n",
       "3        A3            37.117981           0.139039    0.063765\n",
       "4       A13            34.818306           0.130425    0.059815\n",
       "5        A7            26.069323           0.097652    0.044785\n",
       "6        A5            25.925480           0.097113    0.044538\n",
       "7       A14            17.399439           0.065176    0.029891\n",
       "8       A10            17.305044           0.064822    0.029728\n",
       "9       A12             8.257612           0.030932    0.014186\n",
       "10       A6             7.105100           0.026615    0.012206\n",
       "11       A4             6.118043           0.022917    0.010510\n",
       "12      A11             4.930174           0.018468    0.008470\n",
       "13       A1             4.372194           0.016378    0.007511"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml = H2OAutoML(max_runtime_secs = 3600)\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "# train = h2o.H2OFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "T2g-N1P-TSmz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                                        </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_95                    </td><td style=\"text-align: right;\">0.933054</td><td style=\"text-align: right;\"> 0.327768</td><td style=\"text-align: right;\">0.935981</td><td style=\"text-align: right;\">              0.121001</td><td style=\"text-align: right;\">0.310863</td><td style=\"text-align: right;\">0.0966357</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_8_AutoML_1_20220506_142744         </td><td style=\"text-align: right;\">0.932129</td><td style=\"text-align: right;\"> 0.329441</td><td style=\"text-align: right;\">0.92834 </td><td style=\"text-align: right;\">              0.125616</td><td style=\"text-align: right;\">0.30819 </td><td style=\"text-align: right;\">0.0949813</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_110                   </td><td style=\"text-align: right;\">0.929949</td><td style=\"text-align: right;\"> 0.328548</td><td style=\"text-align: right;\">0.921915</td><td style=\"text-align: right;\">              0.124068</td><td style=\"text-align: right;\">0.310866</td><td style=\"text-align: right;\">0.0966378</td></tr>\n",
       "<tr><td>GBM_lr_annealing_selection_AutoML_1_20220506_142744_select_model</td><td style=\"text-align: right;\">0.929588</td><td style=\"text-align: right;\"> 0.324786</td><td style=\"text-align: right;\">0.925239</td><td style=\"text-align: right;\">              0.115303</td><td style=\"text-align: right;\">0.307042</td><td style=\"text-align: right;\">0.0942751</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_73                    </td><td style=\"text-align: right;\">0.929431</td><td style=\"text-align: right;\"> 0.325259</td><td style=\"text-align: right;\">0.927841</td><td style=\"text-align: right;\">              0.114514</td><td style=\"text-align: right;\">0.307959</td><td style=\"text-align: right;\">0.094839 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_60                    </td><td style=\"text-align: right;\">0.929107</td><td style=\"text-align: right;\"> 0.329955</td><td style=\"text-align: right;\">0.922343</td><td style=\"text-align: right;\">              0.11837 </td><td style=\"text-align: right;\">0.311706</td><td style=\"text-align: right;\">0.0971606</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_47                    </td><td style=\"text-align: right;\">0.92901 </td><td style=\"text-align: right;\"> 0.326316</td><td style=\"text-align: right;\">0.918358</td><td style=\"text-align: right;\">              0.115303</td><td style=\"text-align: right;\">0.306278</td><td style=\"text-align: right;\">0.0938059</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_7_AutoML_1_20220506_142744         </td><td style=\"text-align: right;\">0.928867</td><td style=\"text-align: right;\"> 0.332451</td><td style=\"text-align: right;\">0.917199</td><td style=\"text-align: right;\">              0.123046</td><td style=\"text-align: right;\">0.309946</td><td style=\"text-align: right;\">0.0960668</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_20                    </td><td style=\"text-align: right;\">0.92801 </td><td style=\"text-align: right;\"> 0.329704</td><td style=\"text-align: right;\">0.913473</td><td style=\"text-align: right;\">              0.113755</td><td style=\"text-align: right;\">0.309163</td><td style=\"text-align: right;\">0.0955818</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_130                   </td><td style=\"text-align: right;\">0.927732</td><td style=\"text-align: right;\"> 0.329513</td><td style=\"text-align: right;\">0.912448</td><td style=\"text-align: right;\">              0.10829 </td><td style=\"text-align: right;\">0.306994</td><td style=\"text-align: right;\">0.094245 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_80                    </td><td style=\"text-align: right;\">0.927724</td><td style=\"text-align: right;\"> 0.333177</td><td style=\"text-align: right;\">0.913524</td><td style=\"text-align: right;\">              0.118896</td><td style=\"text-align: right;\">0.311319</td><td style=\"text-align: right;\">0.0969198</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_102                   </td><td style=\"text-align: right;\">0.927529</td><td style=\"text-align: right;\"> 0.340282</td><td style=\"text-align: right;\">0.930675</td><td style=\"text-align: right;\">              0.125646</td><td style=\"text-align: right;\">0.315671</td><td style=\"text-align: right;\">0.0996483</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_38                    </td><td style=\"text-align: right;\">0.927484</td><td style=\"text-align: right;\"> 0.330701</td><td style=\"text-align: right;\">0.919519</td><td style=\"text-align: right;\">              0.11837 </td><td style=\"text-align: right;\">0.309772</td><td style=\"text-align: right;\">0.0959586</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_79                    </td><td style=\"text-align: right;\">0.927145</td><td style=\"text-align: right;\"> 0.338814</td><td style=\"text-align: right;\">0.911879</td><td style=\"text-align: right;\">              0.118197</td><td style=\"text-align: right;\">0.31524 </td><td style=\"text-align: right;\">0.0993763</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_117                   </td><td style=\"text-align: right;\">0.926897</td><td style=\"text-align: right;\"> 0.333315</td><td style=\"text-align: right;\">0.925524</td><td style=\"text-align: right;\">              0.112206</td><td style=\"text-align: right;\">0.310109</td><td style=\"text-align: right;\">0.0961676</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_126                   </td><td style=\"text-align: right;\">0.926792</td><td style=\"text-align: right;\"> 0.340214</td><td style=\"text-align: right;\">0.926215</td><td style=\"text-align: right;\">              0.132104</td><td style=\"text-align: right;\">0.319015</td><td style=\"text-align: right;\">0.10177  </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_68                    </td><td style=\"text-align: right;\">0.926288</td><td style=\"text-align: right;\"> 0.338364</td><td style=\"text-align: right;\">0.92075 </td><td style=\"text-align: right;\">              0.117904</td><td style=\"text-align: right;\">0.31225 </td><td style=\"text-align: right;\">0.0975002</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_48                    </td><td style=\"text-align: right;\">0.926281</td><td style=\"text-align: right;\"> 0.331946</td><td style=\"text-align: right;\">0.912949</td><td style=\"text-align: right;\">              0.120182</td><td style=\"text-align: right;\">0.310246</td><td style=\"text-align: right;\">0.0962528</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20220506_142744                                  </td><td style=\"text-align: right;\">0.926243</td><td style=\"text-align: right;\"> 0.401042</td><td style=\"text-align: right;\">0.916648</td><td style=\"text-align: right;\">              0.1184  </td><td style=\"text-align: right;\">0.317897</td><td style=\"text-align: right;\">0.101059 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_3_AutoML_1_20220506_142744         </td><td style=\"text-align: right;\">0.926183</td><td style=\"text-align: right;\"> 0.342004</td><td style=\"text-align: right;\">0.920021</td><td style=\"text-align: right;\">              0.116882</td><td style=\"text-align: right;\">0.313245</td><td style=\"text-align: right;\">0.0981225</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_2                 </td><td style=\"text-align: right;\">0.925619</td><td style=\"text-align: right;\"> 0.338816</td><td style=\"text-align: right;\">0.912376</td><td style=\"text-align: right;\">              0.127954</td><td style=\"text-align: right;\">0.316381</td><td style=\"text-align: right;\">0.100097 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_4_AutoML_1_20220506_142744         </td><td style=\"text-align: right;\">0.925582</td><td style=\"text-align: right;\"> 0.349956</td><td style=\"text-align: right;\">0.919429</td><td style=\"text-align: right;\">              0.122843</td><td style=\"text-align: right;\">0.314527</td><td style=\"text-align: right;\">0.0989274</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_1_20220506_142744         </td><td style=\"text-align: right;\">0.925364</td><td style=\"text-align: right;\"> 0.354309</td><td style=\"text-align: right;\">0.91815 </td><td style=\"text-align: right;\">              0.124624</td><td style=\"text-align: right;\">0.316314</td><td style=\"text-align: right;\">0.100055 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_40                    </td><td style=\"text-align: right;\">0.925123</td><td style=\"text-align: right;\"> 0.33664 </td><td style=\"text-align: right;\">0.900257</td><td style=\"text-align: right;\">              0.116325</td><td style=\"text-align: right;\">0.312327</td><td style=\"text-align: right;\">0.097548 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_5_AutoML_1_20220506_142744         </td><td style=\"text-align: right;\">0.924785</td><td style=\"text-align: right;\"> 0.350687</td><td style=\"text-align: right;\">0.903291</td><td style=\"text-align: right;\">              0.129007</td><td style=\"text-align: right;\">0.313728</td><td style=\"text-align: right;\">0.0984252</td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20220506_142744                                  </td><td style=\"text-align: right;\">0.924717</td><td style=\"text-align: right;\"> 0.336685</td><td style=\"text-align: right;\">0.919398</td><td style=\"text-align: right;\">              0.125646</td><td style=\"text-align: right;\">0.315291</td><td style=\"text-align: right;\">0.0994087</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_116                   </td><td style=\"text-align: right;\">0.924642</td><td style=\"text-align: right;\"> 0.339372</td><td style=\"text-align: right;\">0.91776 </td><td style=\"text-align: right;\">              0.125383</td><td style=\"text-align: right;\">0.315044</td><td style=\"text-align: right;\">0.0992524</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_49                    </td><td style=\"text-align: right;\">0.924477</td><td style=\"text-align: right;\"> 0.331848</td><td style=\"text-align: right;\">0.908982</td><td style=\"text-align: right;\">              0.110131</td><td style=\"text-align: right;\">0.308331</td><td style=\"text-align: right;\">0.0950681</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_53                    </td><td style=\"text-align: right;\">0.924462</td><td style=\"text-align: right;\"> 0.336379</td><td style=\"text-align: right;\">0.904378</td><td style=\"text-align: right;\">              0.120212</td><td style=\"text-align: right;\">0.312141</td><td style=\"text-align: right;\">0.0974319</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_108                   </td><td style=\"text-align: right;\">0.924319</td><td style=\"text-align: right;\"> 0.333781</td><td style=\"text-align: right;\">0.914042</td><td style=\"text-align: right;\">              0.116295</td><td style=\"text-align: right;\">0.309715</td><td style=\"text-align: right;\">0.0959235</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_30                    </td><td style=\"text-align: right;\">0.924221</td><td style=\"text-align: right;\"> 0.347236</td><td style=\"text-align: right;\">0.917279</td><td style=\"text-align: right;\">              0.133156</td><td style=\"text-align: right;\">0.323386</td><td style=\"text-align: right;\">0.104578 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_24                    </td><td style=\"text-align: right;\">0.924063</td><td style=\"text-align: right;\"> 0.344725</td><td style=\"text-align: right;\">0.922819</td><td style=\"text-align: right;\">              0.138034</td><td style=\"text-align: right;\">0.320389</td><td style=\"text-align: right;\">0.102649 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_97                    </td><td style=\"text-align: right;\">0.924056</td><td style=\"text-align: right;\"> 0.348317</td><td style=\"text-align: right;\">0.922174</td><td style=\"text-align: right;\">              0.124594</td><td style=\"text-align: right;\">0.319942</td><td style=\"text-align: right;\">0.102363 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_87                    </td><td style=\"text-align: right;\">0.924018</td><td style=\"text-align: right;\"> 0.336739</td><td style=\"text-align: right;\">0.917997</td><td style=\"text-align: right;\">              0.125879</td><td style=\"text-align: right;\">0.313973</td><td style=\"text-align: right;\">0.0985792</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_45                    </td><td style=\"text-align: right;\">0.923936</td><td style=\"text-align: right;\"> 0.349971</td><td style=\"text-align: right;\">0.903223</td><td style=\"text-align: right;\">              0.128713</td><td style=\"text-align: right;\">0.320852</td><td style=\"text-align: right;\">0.102946 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_33                    </td><td style=\"text-align: right;\">0.923913</td><td style=\"text-align: right;\"> 0.334478</td><td style=\"text-align: right;\">0.91379 </td><td style=\"text-align: right;\">              0.116852</td><td style=\"text-align: right;\">0.308949</td><td style=\"text-align: right;\">0.0954496</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_3                     </td><td style=\"text-align: right;\">0.923785</td><td style=\"text-align: right;\"> 0.333802</td><td style=\"text-align: right;\">0.907198</td><td style=\"text-align: right;\">              0.12921 </td><td style=\"text-align: right;\">0.311378</td><td style=\"text-align: right;\">0.0969561</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_56                    </td><td style=\"text-align: right;\">0.923642</td><td style=\"text-align: right;\"> 0.341099</td><td style=\"text-align: right;\">0.912471</td><td style=\"text-align: right;\">              0.120738</td><td style=\"text-align: right;\">0.314644</td><td style=\"text-align: right;\">0.0990009</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_4            </td><td style=\"text-align: right;\">0.923447</td><td style=\"text-align: right;\"> 0.35632 </td><td style=\"text-align: right;\">0.903629</td><td style=\"text-align: right;\">              0.134178</td><td style=\"text-align: right;\">0.320852</td><td style=\"text-align: right;\">0.102946 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_4                 </td><td style=\"text-align: right;\">0.923424</td><td style=\"text-align: right;\"> 0.335795</td><td style=\"text-align: right;\">0.919694</td><td style=\"text-align: right;\">              0.126902</td><td style=\"text-align: right;\">0.313353</td><td style=\"text-align: right;\">0.0981899</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_63                    </td><td style=\"text-align: right;\">0.923387</td><td style=\"text-align: right;\"> 0.336512</td><td style=\"text-align: right;\">0.910643</td><td style=\"text-align: right;\">              0.119919</td><td style=\"text-align: right;\">0.310994</td><td style=\"text-align: right;\">0.0967171</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_39                    </td><td style=\"text-align: right;\">0.923221</td><td style=\"text-align: right;\"> 0.350181</td><td style=\"text-align: right;\">0.902586</td><td style=\"text-align: right;\">              0.12173 </td><td style=\"text-align: right;\">0.320656</td><td style=\"text-align: right;\">0.10282  </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_22                    </td><td style=\"text-align: right;\">0.923214</td><td style=\"text-align: right;\"> 0.351725</td><td style=\"text-align: right;\">0.915303</td><td style=\"text-align: right;\">              0.130818</td><td style=\"text-align: right;\">0.323647</td><td style=\"text-align: right;\">0.104748 </td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20220506_142744                                  </td><td style=\"text-align: right;\">0.923191</td><td style=\"text-align: right;\"> 0.335551</td><td style=\"text-align: right;\">0.906948</td><td style=\"text-align: right;\">              0.12173 </td><td style=\"text-align: right;\">0.311956</td><td style=\"text-align: right;\">0.0973164</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_1_20220506_142744                              </td><td style=\"text-align: right;\">0.923086</td><td style=\"text-align: right;\"> 0.346943</td><td style=\"text-align: right;\">0.911417</td><td style=\"text-align: right;\">              0.124624</td><td style=\"text-align: right;\">0.317684</td><td style=\"text-align: right;\">0.100923 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_124                   </td><td style=\"text-align: right;\">0.923071</td><td style=\"text-align: right;\"> 0.348555</td><td style=\"text-align: right;\">0.920167</td><td style=\"text-align: right;\">              0.125707</td><td style=\"text-align: right;\">0.32054 </td><td style=\"text-align: right;\">0.102746 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_111                   </td><td style=\"text-align: right;\">0.923056</td><td style=\"text-align: right;\"> 0.347144</td><td style=\"text-align: right;\">0.918311</td><td style=\"text-align: right;\">              0.123339</td><td style=\"text-align: right;\">0.319978</td><td style=\"text-align: right;\">0.102386 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_5                     </td><td style=\"text-align: right;\">0.922936</td><td style=\"text-align: right;\"> 0.342475</td><td style=\"text-align: right;\">0.907124</td><td style=\"text-align: right;\">              0.122286</td><td style=\"text-align: right;\">0.317044</td><td style=\"text-align: right;\">0.100517 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_22                </td><td style=\"text-align: right;\">0.922846</td><td style=\"text-align: right;\"> 0.370719</td><td style=\"text-align: right;\">0.91162 </td><td style=\"text-align: right;\">              0.121467</td><td style=\"text-align: right;\">0.320781</td><td style=\"text-align: right;\">0.102901 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_119                   </td><td style=\"text-align: right;\">0.922725</td><td style=\"text-align: right;\"> 0.338111</td><td style=\"text-align: right;\">0.91026 </td><td style=\"text-align: right;\">              0.122316</td><td style=\"text-align: right;\">0.313025</td><td style=\"text-align: right;\">0.0979844</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_92                    </td><td style=\"text-align: right;\">0.92241 </td><td style=\"text-align: right;\"> 0.341969</td><td style=\"text-align: right;\">0.902384</td><td style=\"text-align: right;\">              0.117085</td><td style=\"text-align: right;\">0.316266</td><td style=\"text-align: right;\">0.100024 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_4                     </td><td style=\"text-align: right;\">0.922071</td><td style=\"text-align: right;\"> 0.341424</td><td style=\"text-align: right;\">0.905246</td><td style=\"text-align: right;\">              0.11837 </td><td style=\"text-align: right;\">0.314824</td><td style=\"text-align: right;\">0.0991144</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_131                   </td><td style=\"text-align: right;\">0.921929</td><td style=\"text-align: right;\"> 0.350045</td><td style=\"text-align: right;\">0.918532</td><td style=\"text-align: right;\">              0.12512 </td><td style=\"text-align: right;\">0.321489</td><td style=\"text-align: right;\">0.103355 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_86                    </td><td style=\"text-align: right;\">0.921883</td><td style=\"text-align: right;\"> 0.339486</td><td style=\"text-align: right;\">0.908086</td><td style=\"text-align: right;\">              0.118663</td><td style=\"text-align: right;\">0.312255</td><td style=\"text-align: right;\">0.0975031</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_105                   </td><td style=\"text-align: right;\">0.921816</td><td style=\"text-align: right;\"> 0.339998</td><td style=\"text-align: right;\">0.901411</td><td style=\"text-align: right;\">              0.124564</td><td style=\"text-align: right;\">0.313879</td><td style=\"text-align: right;\">0.0985198</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20220506_142744                                  </td><td style=\"text-align: right;\">0.921801</td><td style=\"text-align: right;\"> 0.341348</td><td style=\"text-align: right;\">0.912463</td><td style=\"text-align: right;\">              0.116852</td><td style=\"text-align: right;\">0.315075</td><td style=\"text-align: right;\">0.0992726</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_6_AutoML_1_20220506_142744            </td><td style=\"text-align: right;\">0.921793</td><td style=\"text-align: right;\"> 0.346021</td><td style=\"text-align: right;\">0.908538</td><td style=\"text-align: right;\">              0.126113</td><td style=\"text-align: right;\">0.318724</td><td style=\"text-align: right;\">0.101585 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_49           </td><td style=\"text-align: right;\">0.921703</td><td style=\"text-align: right;\"> 0.403924</td><td style=\"text-align: right;\">0.904373</td><td style=\"text-align: right;\">              0.132863</td><td style=\"text-align: right;\">0.329519</td><td style=\"text-align: right;\">0.108583 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_5                 </td><td style=\"text-align: right;\">0.921658</td><td style=\"text-align: right;\"> 0.339106</td><td style=\"text-align: right;\">0.911053</td><td style=\"text-align: right;\">              0.120475</td><td style=\"text-align: right;\">0.313327</td><td style=\"text-align: right;\">0.0981736</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_13                    </td><td style=\"text-align: right;\">0.92156 </td><td style=\"text-align: right;\"> 0.353036</td><td style=\"text-align: right;\">0.918682</td><td style=\"text-align: right;\">              0.136486</td><td style=\"text-align: right;\">0.323165</td><td style=\"text-align: right;\">0.104436 </td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_2_AutoML_1_20220506_142744            </td><td style=\"text-align: right;\">0.92144 </td><td style=\"text-align: right;\"> 0.349097</td><td style=\"text-align: right;\">0.905439</td><td style=\"text-align: right;\">              0.127428</td><td style=\"text-align: right;\">0.315824</td><td style=\"text-align: right;\">0.0997446</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_65                    </td><td style=\"text-align: right;\">0.921432</td><td style=\"text-align: right;\"> 0.343041</td><td style=\"text-align: right;\">0.906988</td><td style=\"text-align: right;\">              0.132833</td><td style=\"text-align: right;\">0.318596</td><td style=\"text-align: right;\">0.101503 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_7                 </td><td style=\"text-align: right;\">0.921432</td><td style=\"text-align: right;\"> 0.341866</td><td style=\"text-align: right;\">0.911673</td><td style=\"text-align: right;\">              0.127924</td><td style=\"text-align: right;\">0.316474</td><td style=\"text-align: right;\">0.100155 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_1            </td><td style=\"text-align: right;\">0.921402</td><td style=\"text-align: right;\"> 0.370272</td><td style=\"text-align: right;\">0.901306</td><td style=\"text-align: right;\">              0.128946</td><td style=\"text-align: right;\">0.323254</td><td style=\"text-align: right;\">0.104493 </td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20220506_142744            </td><td style=\"text-align: right;\">0.921154</td><td style=\"text-align: right;\"> 0.346473</td><td style=\"text-align: right;\">0.91221 </td><td style=\"text-align: right;\">              0.124331</td><td style=\"text-align: right;\">0.314658</td><td style=\"text-align: right;\">0.0990099</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_43                    </td><td style=\"text-align: right;\">0.921109</td><td style=\"text-align: right;\"> 0.342461</td><td style=\"text-align: right;\">0.911621</td><td style=\"text-align: right;\">              0.120475</td><td style=\"text-align: right;\">0.31506 </td><td style=\"text-align: right;\">0.0992629</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_100                   </td><td style=\"text-align: right;\">0.920688</td><td style=\"text-align: right;\"> 0.339568</td><td style=\"text-align: right;\">0.894032</td><td style=\"text-align: right;\">              0.113228</td><td style=\"text-align: right;\">0.31346 </td><td style=\"text-align: right;\">0.0982573</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_89                    </td><td style=\"text-align: right;\">0.920666</td><td style=\"text-align: right;\"> 0.348175</td><td style=\"text-align: right;\">0.912428</td><td style=\"text-align: right;\">              0.130585</td><td style=\"text-align: right;\">0.319798</td><td style=\"text-align: right;\">0.102271 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_11                    </td><td style=\"text-align: right;\">0.920643</td><td style=\"text-align: right;\"> 0.341662</td><td style=\"text-align: right;\">0.908567</td><td style=\"text-align: right;\">              0.118663</td><td style=\"text-align: right;\">0.315438</td><td style=\"text-align: right;\">0.0995013</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_9            </td><td style=\"text-align: right;\">0.920545</td><td style=\"text-align: right;\"> 0.369865</td><td style=\"text-align: right;\">0.894031</td><td style=\"text-align: right;\">              0.1461  </td><td style=\"text-align: right;\">0.328855</td><td style=\"text-align: right;\">0.108146 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_120                   </td><td style=\"text-align: right;\">0.920515</td><td style=\"text-align: right;\"> 0.343661</td><td style=\"text-align: right;\">0.912342</td><td style=\"text-align: right;\">              0.123572</td><td style=\"text-align: right;\">0.317316</td><td style=\"text-align: right;\">0.10069  </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_62                    </td><td style=\"text-align: right;\">0.920493</td><td style=\"text-align: right;\"> 0.342156</td><td style=\"text-align: right;\">0.91344 </td><td style=\"text-align: right;\">              0.125323</td><td style=\"text-align: right;\">0.316215</td><td style=\"text-align: right;\">0.099992 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_10                    </td><td style=\"text-align: right;\">0.920478</td><td style=\"text-align: right;\"> 0.346349</td><td style=\"text-align: right;\">0.897327</td><td style=\"text-align: right;\">              0.113725</td><td style=\"text-align: right;\">0.316399</td><td style=\"text-align: right;\">0.100109 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_72                    </td><td style=\"text-align: right;\">0.920087</td><td style=\"text-align: right;\"> 0.351464</td><td style=\"text-align: right;\">0.895493</td><td style=\"text-align: right;\">              0.122782</td><td style=\"text-align: right;\">0.320769</td><td style=\"text-align: right;\">0.102893 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_77                    </td><td style=\"text-align: right;\">0.920087</td><td style=\"text-align: right;\"> 0.340925</td><td style=\"text-align: right;\">0.905097</td><td style=\"text-align: right;\">              0.122782</td><td style=\"text-align: right;\">0.314867</td><td style=\"text-align: right;\">0.0991409</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_107                   </td><td style=\"text-align: right;\">0.920079</td><td style=\"text-align: right;\"> 0.352547</td><td style=\"text-align: right;\">0.894576</td><td style=\"text-align: right;\">              0.119452</td><td style=\"text-align: right;\">0.321251</td><td style=\"text-align: right;\">0.103202 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_59                    </td><td style=\"text-align: right;\">0.920034</td><td style=\"text-align: right;\"> 0.347866</td><td style=\"text-align: right;\">0.892749</td><td style=\"text-align: right;\">              0.119949</td><td style=\"text-align: right;\">0.318819</td><td style=\"text-align: right;\">0.101645 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_50                    </td><td style=\"text-align: right;\">0.919944</td><td style=\"text-align: right;\"> 0.351524</td><td style=\"text-align: right;\">0.9086  </td><td style=\"text-align: right;\">              0.124098</td><td style=\"text-align: right;\">0.322386</td><td style=\"text-align: right;\">0.103933 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_26           </td><td style=\"text-align: right;\">0.919786</td><td style=\"text-align: right;\"> 0.401525</td><td style=\"text-align: right;\">0.909237</td><td style=\"text-align: right;\">              0.135434</td><td style=\"text-align: right;\">0.333514</td><td style=\"text-align: right;\">0.111232 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_1                     </td><td style=\"text-align: right;\">0.919779</td><td style=\"text-align: right;\"> 0.353166</td><td style=\"text-align: right;\">0.909869</td><td style=\"text-align: right;\">              0.126669</td><td style=\"text-align: right;\">0.322542</td><td style=\"text-align: right;\">0.104033 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_35                    </td><td style=\"text-align: right;\">0.919779</td><td style=\"text-align: right;\"> 0.353216</td><td style=\"text-align: right;\">0.905586</td><td style=\"text-align: right;\">              0.122286</td><td style=\"text-align: right;\">0.322959</td><td style=\"text-align: right;\">0.104302 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_101                   </td><td style=\"text-align: right;\">0.919636</td><td style=\"text-align: right;\"> 0.360162</td><td style=\"text-align: right;\">0.919896</td><td style=\"text-align: right;\">              0.132134</td><td style=\"text-align: right;\">0.325955</td><td style=\"text-align: right;\">0.106246 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_36                    </td><td style=\"text-align: right;\">0.919471</td><td style=\"text-align: right;\"> 0.345588</td><td style=\"text-align: right;\">0.907157</td><td style=\"text-align: right;\">              0.120971</td><td style=\"text-align: right;\">0.317794</td><td style=\"text-align: right;\">0.100993 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_27                    </td><td style=\"text-align: right;\">0.919455</td><td style=\"text-align: right;\"> 0.357074</td><td style=\"text-align: right;\">0.911867</td><td style=\"text-align: right;\">              0.138884</td><td style=\"text-align: right;\">0.329545</td><td style=\"text-align: right;\">0.1086   </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_29                </td><td style=\"text-align: right;\">0.919448</td><td style=\"text-align: right;\"> 0.34561 </td><td style=\"text-align: right;\">0.911081</td><td style=\"text-align: right;\">              0.129007</td><td style=\"text-align: right;\">0.3193  </td><td style=\"text-align: right;\">0.101952 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_70                    </td><td style=\"text-align: right;\">0.919418</td><td style=\"text-align: right;\"> 0.350047</td><td style=\"text-align: right;\">0.896521</td><td style=\"text-align: right;\">              0.12924 </td><td style=\"text-align: right;\">0.321162</td><td style=\"text-align: right;\">0.103145 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_1                 </td><td style=\"text-align: right;\">0.919373</td><td style=\"text-align: right;\"> 0.389644</td><td style=\"text-align: right;\">0.907894</td><td style=\"text-align: right;\">              0.128217</td><td style=\"text-align: right;\">0.331142</td><td style=\"text-align: right;\">0.109655 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_128                   </td><td style=\"text-align: right;\">0.91926 </td><td style=\"text-align: right;\"> 0.353201</td><td style=\"text-align: right;\">0.889311</td><td style=\"text-align: right;\">              0.126669</td><td style=\"text-align: right;\">0.323119</td><td style=\"text-align: right;\">0.104406 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_106                   </td><td style=\"text-align: right;\">0.919125</td><td style=\"text-align: right;\"> 0.344663</td><td style=\"text-align: right;\">0.891216</td><td style=\"text-align: right;\">              0.117378</td><td style=\"text-align: right;\">0.317044</td><td style=\"text-align: right;\">0.100517 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_104                   </td><td style=\"text-align: right;\">0.91908 </td><td style=\"text-align: right;\"> 0.349504</td><td style=\"text-align: right;\">0.907719</td><td style=\"text-align: right;\">              0.139057</td><td style=\"text-align: right;\">0.32242 </td><td style=\"text-align: right;\">0.103955 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_31           </td><td style=\"text-align: right;\">0.918937</td><td style=\"text-align: right;\"> 0.386663</td><td style=\"text-align: right;\">0.889081</td><td style=\"text-align: right;\">              0.129826</td><td style=\"text-align: right;\">0.321764</td><td style=\"text-align: right;\">0.103532 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_78                    </td><td style=\"text-align: right;\">0.918914</td><td style=\"text-align: right;\"> 0.348863</td><td style=\"text-align: right;\">0.892448</td><td style=\"text-align: right;\">              0.12509 </td><td style=\"text-align: right;\">0.318405</td><td style=\"text-align: right;\">0.101382 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_37                    </td><td style=\"text-align: right;\">0.918719</td><td style=\"text-align: right;\"> 0.34608 </td><td style=\"text-align: right;\">0.897965</td><td style=\"text-align: right;\">              0.120941</td><td style=\"text-align: right;\">0.315876</td><td style=\"text-align: right;\">0.0997776</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_7                     </td><td style=\"text-align: right;\">0.918696</td><td style=\"text-align: right;\"> 0.356949</td><td style=\"text-align: right;\">0.894461</td><td style=\"text-align: right;\">              0.122843</td><td style=\"text-align: right;\">0.323751</td><td style=\"text-align: right;\">0.104815 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_114                   </td><td style=\"text-align: right;\">0.918696</td><td style=\"text-align: right;\"> 0.347018</td><td style=\"text-align: right;\">0.901629</td><td style=\"text-align: right;\">              0.122256</td><td style=\"text-align: right;\">0.318324</td><td style=\"text-align: right;\">0.10133  </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_20                </td><td style=\"text-align: right;\">0.918538</td><td style=\"text-align: right;\"> 0.359238</td><td style=\"text-align: right;\">0.906016</td><td style=\"text-align: right;\">              0.129503</td><td style=\"text-align: right;\">0.325329</td><td style=\"text-align: right;\">0.105839 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_112                   </td><td style=\"text-align: right;\">0.918433</td><td style=\"text-align: right;\"> 0.346283</td><td style=\"text-align: right;\">0.899951</td><td style=\"text-align: right;\">              0.12509 </td><td style=\"text-align: right;\">0.315897</td><td style=\"text-align: right;\">0.0997907</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_88                    </td><td style=\"text-align: right;\">0.918418</td><td style=\"text-align: right;\"> 0.351949</td><td style=\"text-align: right;\">0.897799</td><td style=\"text-align: right;\">              0.124361</td><td style=\"text-align: right;\">0.321239</td><td style=\"text-align: right;\">0.103195 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_27                </td><td style=\"text-align: right;\">0.918298</td><td style=\"text-align: right;\"> 0.352259</td><td style=\"text-align: right;\">0.909679</td><td style=\"text-align: right;\">              0.125646</td><td style=\"text-align: right;\">0.321341</td><td style=\"text-align: right;\">0.10326  </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_55                    </td><td style=\"text-align: right;\">0.91829 </td><td style=\"text-align: right;\"> 0.347674</td><td style=\"text-align: right;\">0.898235</td><td style=\"text-align: right;\">              0.118137</td><td style=\"text-align: right;\">0.31764 </td><td style=\"text-align: right;\">0.100895 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_93                    </td><td style=\"text-align: right;\">0.9182  </td><td style=\"text-align: right;\"> 0.354148</td><td style=\"text-align: right;\">0.895073</td><td style=\"text-align: right;\">              0.121527</td><td style=\"text-align: right;\">0.322047</td><td style=\"text-align: right;\">0.103714 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_67                    </td><td style=\"text-align: right;\">0.918185</td><td style=\"text-align: right;\"> 0.360925</td><td style=\"text-align: right;\">0.90556 </td><td style=\"text-align: right;\">              0.125413</td><td style=\"text-align: right;\">0.326946</td><td style=\"text-align: right;\">0.106894 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_1            </td><td style=\"text-align: right;\">0.91802 </td><td style=\"text-align: right;\"> 0.371516</td><td style=\"text-align: right;\">0.898781</td><td style=\"text-align: right;\">              0.129473</td><td style=\"text-align: right;\">0.327594</td><td style=\"text-align: right;\">0.107318 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_15                </td><td style=\"text-align: right;\">0.917914</td><td style=\"text-align: right;\"> 0.352939</td><td style=\"text-align: right;\">0.905651</td><td style=\"text-align: right;\">              0.119919</td><td style=\"text-align: right;\">0.315572</td><td style=\"text-align: right;\">0.0995858</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_66                    </td><td style=\"text-align: right;\">0.917884</td><td style=\"text-align: right;\"> 0.367768</td><td style=\"text-align: right;\">0.897573</td><td style=\"text-align: right;\">              0.136253</td><td style=\"text-align: right;\">0.331079</td><td style=\"text-align: right;\">0.109613 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_82                    </td><td style=\"text-align: right;\">0.917824</td><td style=\"text-align: right;\"> 0.352472</td><td style=\"text-align: right;\">0.889807</td><td style=\"text-align: right;\">              0.130788</td><td style=\"text-align: right;\">0.321019</td><td style=\"text-align: right;\">0.103053 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_69                    </td><td style=\"text-align: right;\">0.917809</td><td style=\"text-align: right;\"> 0.345972</td><td style=\"text-align: right;\">0.900362</td><td style=\"text-align: right;\">              0.12176 </td><td style=\"text-align: right;\">0.317702</td><td style=\"text-align: right;\">0.100935 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_9                 </td><td style=\"text-align: right;\">0.917742</td><td style=\"text-align: right;\"> 0.358536</td><td style=\"text-align: right;\">0.901355</td><td style=\"text-align: right;\">              0.121497</td><td style=\"text-align: right;\">0.318518</td><td style=\"text-align: right;\">0.101453 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_8                     </td><td style=\"text-align: right;\">0.917644</td><td style=\"text-align: right;\"> 0.365361</td><td style=\"text-align: right;\">0.912409</td><td style=\"text-align: right;\">              0.126669</td><td style=\"text-align: right;\">0.328718</td><td style=\"text-align: right;\">0.108056 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_84                    </td><td style=\"text-align: right;\">0.917531</td><td style=\"text-align: right;\"> 0.359111</td><td style=\"text-align: right;\">0.885493</td><td style=\"text-align: right;\">              0.129999</td><td style=\"text-align: right;\">0.324237</td><td style=\"text-align: right;\">0.105129 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_16           </td><td style=\"text-align: right;\">0.917524</td><td style=\"text-align: right;\"> 0.392193</td><td style=\"text-align: right;\">0.888625</td><td style=\"text-align: right;\">              0.129007</td><td style=\"text-align: right;\">0.322574</td><td style=\"text-align: right;\">0.104054 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_12                    </td><td style=\"text-align: right;\">0.917125</td><td style=\"text-align: right;\"> 0.351361</td><td style=\"text-align: right;\">0.891185</td><td style=\"text-align: right;\">              0.124887</td><td style=\"text-align: right;\">0.321459</td><td style=\"text-align: right;\">0.103336 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_21                </td><td style=\"text-align: right;\">0.916997</td><td style=\"text-align: right;\"> 0.345673</td><td style=\"text-align: right;\">0.898987</td><td style=\"text-align: right;\">              0.11504 </td><td style=\"text-align: right;\">0.316304</td><td style=\"text-align: right;\">0.100048 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_9            </td><td style=\"text-align: right;\">0.91699 </td><td style=\"text-align: right;\"> 0.386243</td><td style=\"text-align: right;\">0.908468</td><td style=\"text-align: right;\">              0.13596 </td><td style=\"text-align: right;\">0.325509</td><td style=\"text-align: right;\">0.105956 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_54                    </td><td style=\"text-align: right;\">0.916922</td><td style=\"text-align: right;\"> 0.363675</td><td style=\"text-align: right;\">0.902026</td><td style=\"text-align: right;\">              0.133126</td><td style=\"text-align: right;\">0.327813</td><td style=\"text-align: right;\">0.107462 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_122                   </td><td style=\"text-align: right;\">0.916915</td><td style=\"text-align: right;\"> 0.345572</td><td style=\"text-align: right;\">0.884479</td><td style=\"text-align: right;\">              0.118633</td><td style=\"text-align: right;\">0.315465</td><td style=\"text-align: right;\">0.0995183</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_10           </td><td style=\"text-align: right;\">0.916704</td><td style=\"text-align: right;\"> 0.434297</td><td style=\"text-align: right;\">0.891526</td><td style=\"text-align: right;\">              0.133126</td><td style=\"text-align: right;\">0.34007 </td><td style=\"text-align: right;\">0.115648 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_32           </td><td style=\"text-align: right;\">0.916659</td><td style=\"text-align: right;\"> 0.419274</td><td style=\"text-align: right;\">0.878524</td><td style=\"text-align: right;\">              0.135524</td><td style=\"text-align: right;\">0.330792</td><td style=\"text-align: right;\">0.109423 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_8            </td><td style=\"text-align: right;\">0.916404</td><td style=\"text-align: right;\"> 0.411132</td><td style=\"text-align: right;\">0.889859</td><td style=\"text-align: right;\">              0.131314</td><td style=\"text-align: right;\">0.330739</td><td style=\"text-align: right;\">0.109388 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_21           </td><td style=\"text-align: right;\">0.916298</td><td style=\"text-align: right;\"> 0.390376</td><td style=\"text-align: right;\">0.906492</td><td style=\"text-align: right;\">              0.138004</td><td style=\"text-align: right;\">0.327443</td><td style=\"text-align: right;\">0.107219 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_127                   </td><td style=\"text-align: right;\">0.916283</td><td style=\"text-align: right;\"> 0.362192</td><td style=\"text-align: right;\">0.888299</td><td style=\"text-align: right;\">              0.129766</td><td style=\"text-align: right;\">0.326531</td><td style=\"text-align: right;\">0.106623 </td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_1_20220506_142744            </td><td style=\"text-align: right;\">0.916283</td><td style=\"text-align: right;\"> 0.37316 </td><td style=\"text-align: right;\">0.886082</td><td style=\"text-align: right;\">              0.129999</td><td style=\"text-align: right;\">0.331528</td><td style=\"text-align: right;\">0.109911 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_53           </td><td style=\"text-align: right;\">0.916103</td><td style=\"text-align: right;\"> 0.390691</td><td style=\"text-align: right;\">0.889828</td><td style=\"text-align: right;\">              0.135667</td><td style=\"text-align: right;\">0.332992</td><td style=\"text-align: right;\">0.110884 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_44                    </td><td style=\"text-align: right;\">0.916095</td><td style=\"text-align: right;\"> 0.357731</td><td style=\"text-align: right;\">0.882279</td><td style=\"text-align: right;\">              0.116558</td><td style=\"text-align: right;\">0.32214 </td><td style=\"text-align: right;\">0.103774 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_64                    </td><td style=\"text-align: right;\">0.91608 </td><td style=\"text-align: right;\"> 0.347872</td><td style=\"text-align: right;\">0.898111</td><td style=\"text-align: right;\">              0.126639</td><td style=\"text-align: right;\">0.319412</td><td style=\"text-align: right;\">0.102024 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_46                    </td><td style=\"text-align: right;\">0.916065</td><td style=\"text-align: right;\"> 0.357528</td><td style=\"text-align: right;\">0.901904</td><td style=\"text-align: right;\">              0.126932</td><td style=\"text-align: right;\">0.323113</td><td style=\"text-align: right;\">0.104402 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_10                </td><td style=\"text-align: right;\">0.91605 </td><td style=\"text-align: right;\"> 0.359702</td><td style=\"text-align: right;\">0.896068</td><td style=\"text-align: right;\">              0.127691</td><td style=\"text-align: right;\">0.324427</td><td style=\"text-align: right;\">0.105253 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_61                    </td><td style=\"text-align: right;\">0.916028</td><td style=\"text-align: right;\"> 0.352622</td><td style=\"text-align: right;\">0.890419</td><td style=\"text-align: right;\">              0.125383</td><td style=\"text-align: right;\">0.321339</td><td style=\"text-align: right;\">0.103259 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_10           </td><td style=\"text-align: right;\">0.916005</td><td style=\"text-align: right;\"> 0.446302</td><td style=\"text-align: right;\">0.893567</td><td style=\"text-align: right;\">              0.145544</td><td style=\"text-align: right;\">0.341599</td><td style=\"text-align: right;\">0.11669  </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_22           </td><td style=\"text-align: right;\">0.91581 </td><td style=\"text-align: right;\"> 0.4206  </td><td style=\"text-align: right;\">0.886796</td><td style=\"text-align: right;\">              0.136982</td><td style=\"text-align: right;\">0.335974</td><td style=\"text-align: right;\">0.112878 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_13           </td><td style=\"text-align: right;\">0.915614</td><td style=\"text-align: right;\"> 0.423669</td><td style=\"text-align: right;\">0.879439</td><td style=\"text-align: right;\">              0.130555</td><td style=\"text-align: right;\">0.331899</td><td style=\"text-align: right;\">0.110157 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_21                    </td><td style=\"text-align: right;\">0.915374</td><td style=\"text-align: right;\"> 0.355683</td><td style=\"text-align: right;\">0.885744</td><td style=\"text-align: right;\">              0.126406</td><td style=\"text-align: right;\">0.323764</td><td style=\"text-align: right;\">0.104823 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_42                    </td><td style=\"text-align: right;\">0.915321</td><td style=\"text-align: right;\"> 0.364938</td><td style=\"text-align: right;\">0.911526</td><td style=\"text-align: right;\">              0.132397</td><td style=\"text-align: right;\">0.326439</td><td style=\"text-align: right;\">0.106562 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_57           </td><td style=\"text-align: right;\">0.915276</td><td style=\"text-align: right;\"> 0.417059</td><td style=\"text-align: right;\">0.901986</td><td style=\"text-align: right;\">              0.141425</td><td style=\"text-align: right;\">0.338992</td><td style=\"text-align: right;\">0.114916 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_25           </td><td style=\"text-align: right;\">0.915208</td><td style=\"text-align: right;\"> 0.394712</td><td style=\"text-align: right;\">0.897804</td><td style=\"text-align: right;\">              0.141425</td><td style=\"text-align: right;\">0.329532</td><td style=\"text-align: right;\">0.108591 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_125                   </td><td style=\"text-align: right;\">0.915088</td><td style=\"text-align: right;\"> 0.364187</td><td style=\"text-align: right;\">0.901138</td><td style=\"text-align: right;\">              0.133419</td><td style=\"text-align: right;\">0.328452</td><td style=\"text-align: right;\">0.107881 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_3            </td><td style=\"text-align: right;\">0.915066</td><td style=\"text-align: right;\"> 0.431873</td><td style=\"text-align: right;\">0.881972</td><td style=\"text-align: right;\">              0.132337</td><td style=\"text-align: right;\">0.330572</td><td style=\"text-align: right;\">0.109278 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_91                    </td><td style=\"text-align: right;\">0.915043</td><td style=\"text-align: right;\"> 0.347868</td><td style=\"text-align: right;\">0.89507 </td><td style=\"text-align: right;\">              0.126932</td><td style=\"text-align: right;\">0.31682 </td><td style=\"text-align: right;\">0.100375 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_12           </td><td style=\"text-align: right;\">0.91502 </td><td style=\"text-align: right;\"> 0.464949</td><td style=\"text-align: right;\">0.896727</td><td style=\"text-align: right;\">              0.135697</td><td style=\"text-align: right;\">0.344637</td><td style=\"text-align: right;\">0.118775 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_123                   </td><td style=\"text-align: right;\">0.915005</td><td style=\"text-align: right;\"> 0.361493</td><td style=\"text-align: right;\">0.915593</td><td style=\"text-align: right;\">              0.130848</td><td style=\"text-align: right;\">0.327541</td><td style=\"text-align: right;\">0.107283 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_74                    </td><td style=\"text-align: right;\">0.91481 </td><td style=\"text-align: right;\"> 0.367987</td><td style=\"text-align: right;\">0.892142</td><td style=\"text-align: right;\">              0.13269 </td><td style=\"text-align: right;\">0.330351</td><td style=\"text-align: right;\">0.109132 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_29                    </td><td style=\"text-align: right;\">0.914502</td><td style=\"text-align: right;\"> 0.359104</td><td style=\"text-align: right;\">0.881372</td><td style=\"text-align: right;\">              0.125646</td><td style=\"text-align: right;\">0.323825</td><td style=\"text-align: right;\">0.104863 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_35                </td><td style=\"text-align: right;\">0.914374</td><td style=\"text-align: right;\"> 0.36199 </td><td style=\"text-align: right;\">0.895758</td><td style=\"text-align: right;\">              0.127954</td><td style=\"text-align: right;\">0.322382</td><td style=\"text-align: right;\">0.10393  </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_32                    </td><td style=\"text-align: right;\">0.914276</td><td style=\"text-align: right;\"> 0.359105</td><td style=\"text-align: right;\">0.88399 </td><td style=\"text-align: right;\">              0.124331</td><td style=\"text-align: right;\">0.32387 </td><td style=\"text-align: right;\">0.104892 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_6                 </td><td style=\"text-align: right;\">0.914126</td><td style=\"text-align: right;\"> 0.360131</td><td style=\"text-align: right;\">0.885693</td><td style=\"text-align: right;\">              0.142154</td><td style=\"text-align: right;\">0.326761</td><td style=\"text-align: right;\">0.106773 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_59           </td><td style=\"text-align: right;\">0.913961</td><td style=\"text-align: right;\"> 0.406523</td><td style=\"text-align: right;\">0.902184</td><td style=\"text-align: right;\">              0.140726</td><td style=\"text-align: right;\">0.33577 </td><td style=\"text-align: right;\">0.112741 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_44           </td><td style=\"text-align: right;\">0.913893</td><td style=\"text-align: right;\"> 0.389398</td><td style=\"text-align: right;\">0.898037</td><td style=\"text-align: right;\">              0.1461  </td><td style=\"text-align: right;\">0.335223</td><td style=\"text-align: right;\">0.112375 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_26                    </td><td style=\"text-align: right;\">0.91381 </td><td style=\"text-align: right;\"> 0.367768</td><td style=\"text-align: right;\">0.896272</td><td style=\"text-align: right;\">              0.131638</td><td style=\"text-align: right;\">0.330609</td><td style=\"text-align: right;\">0.109302 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_17                    </td><td style=\"text-align: right;\">0.91372 </td><td style=\"text-align: right;\"> 0.354628</td><td style=\"text-align: right;\">0.890383</td><td style=\"text-align: right;\">              0.117348</td><td style=\"text-align: right;\">0.322407</td><td style=\"text-align: right;\">0.103946 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_51                    </td><td style=\"text-align: right;\">0.913585</td><td style=\"text-align: right;\"> 0.354821</td><td style=\"text-align: right;\">0.883126</td><td style=\"text-align: right;\">              0.119949</td><td style=\"text-align: right;\">0.321696</td><td style=\"text-align: right;\">0.103488 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_3            </td><td style=\"text-align: right;\">0.912961</td><td style=\"text-align: right;\"> 0.396993</td><td style=\"text-align: right;\">0.881674</td><td style=\"text-align: right;\">              0.137801</td><td style=\"text-align: right;\">0.329765</td><td style=\"text-align: right;\">0.108745 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_30                </td><td style=\"text-align: right;\">0.912946</td><td style=\"text-align: right;\"> 0.361107</td><td style=\"text-align: right;\">0.872715</td><td style=\"text-align: right;\">              0.13517 </td><td style=\"text-align: right;\">0.326193</td><td style=\"text-align: right;\">0.106402 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_42           </td><td style=\"text-align: right;\">0.912863</td><td style=\"text-align: right;\"> 0.426278</td><td style=\"text-align: right;\">0.901142</td><td style=\"text-align: right;\">              0.144259</td><td style=\"text-align: right;\">0.33974 </td><td style=\"text-align: right;\">0.115423 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_3                 </td><td style=\"text-align: right;\">0.912472</td><td style=\"text-align: right;\"> 0.362453</td><td style=\"text-align: right;\">0.904382</td><td style=\"text-align: right;\">              0.127165</td><td style=\"text-align: right;\">0.325753</td><td style=\"text-align: right;\">0.106115 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_24           </td><td style=\"text-align: right;\">0.912322</td><td style=\"text-align: right;\"> 0.445541</td><td style=\"text-align: right;\">0.877368</td><td style=\"text-align: right;\">              0.132073</td><td style=\"text-align: right;\">0.335049</td><td style=\"text-align: right;\">0.112258 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_10           </td><td style=\"text-align: right;\">0.912096</td><td style=\"text-align: right;\"> 0.38303 </td><td style=\"text-align: right;\">0.875958</td><td style=\"text-align: right;\">              0.129736</td><td style=\"text-align: right;\">0.32753 </td><td style=\"text-align: right;\">0.107276 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_118                   </td><td style=\"text-align: right;\">0.912021</td><td style=\"text-align: right;\"> 0.375303</td><td style=\"text-align: right;\">0.903258</td><td style=\"text-align: right;\">              0.144086</td><td style=\"text-align: right;\">0.335316</td><td style=\"text-align: right;\">0.112437 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_113                   </td><td style=\"text-align: right;\">0.911563</td><td style=\"text-align: right;\"> 0.359297</td><td style=\"text-align: right;\">0.881934</td><td style=\"text-align: right;\">              0.124857</td><td style=\"text-align: right;\">0.32315 </td><td style=\"text-align: right;\">0.104426 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_7            </td><td style=\"text-align: right;\">0.91145 </td><td style=\"text-align: right;\"> 0.396224</td><td style=\"text-align: right;\">0.89294 </td><td style=\"text-align: right;\">              0.137801</td><td style=\"text-align: right;\">0.333582</td><td style=\"text-align: right;\">0.111277 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_71                    </td><td style=\"text-align: right;\">0.91139 </td><td style=\"text-align: right;\"> 0.358343</td><td style=\"text-align: right;\">0.887619</td><td style=\"text-align: right;\">              0.130029</td><td style=\"text-align: right;\">0.324309</td><td style=\"text-align: right;\">0.105176 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_17           </td><td style=\"text-align: right;\">0.910856</td><td style=\"text-align: right;\"> 0.418825</td><td style=\"text-align: right;\">0.881112</td><td style=\"text-align: right;\">              0.137801</td><td style=\"text-align: right;\">0.332395</td><td style=\"text-align: right;\">0.110486 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_98                    </td><td style=\"text-align: right;\">0.910758</td><td style=\"text-align: right;\"> 0.36685 </td><td style=\"text-align: right;\">0.87511 </td><td style=\"text-align: right;\">              0.126729</td><td style=\"text-align: right;\">0.328632</td><td style=\"text-align: right;\">0.107999 </td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_1_20220506_142744                              </td><td style=\"text-align: right;\">0.910736</td><td style=\"text-align: right;\"> 0.365136</td><td style=\"text-align: right;\">0.891078</td><td style=\"text-align: right;\">              0.131081</td><td style=\"text-align: right;\">0.32829 </td><td style=\"text-align: right;\">0.107774 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_33           </td><td style=\"text-align: right;\">0.910195</td><td style=\"text-align: right;\"> 0.414734</td><td style=\"text-align: right;\">0.876745</td><td style=\"text-align: right;\">              0.133359</td><td style=\"text-align: right;\">0.329578</td><td style=\"text-align: right;\">0.108622 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_81                    </td><td style=\"text-align: right;\">0.910059</td><td style=\"text-align: right;\"> 0.362166</td><td style=\"text-align: right;\">0.886612</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.326726</td><td style=\"text-align: right;\">0.10675  </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_45           </td><td style=\"text-align: right;\">0.909969</td><td style=\"text-align: right;\"> 0.383823</td><td style=\"text-align: right;\">0.880104</td><td style=\"text-align: right;\">              0.13184 </td><td style=\"text-align: right;\">0.333392</td><td style=\"text-align: right;\">0.11115  </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_103                   </td><td style=\"text-align: right;\">0.909909</td><td style=\"text-align: right;\"> 0.373371</td><td style=\"text-align: right;\">0.874836</td><td style=\"text-align: right;\">              0.124391</td><td style=\"text-align: right;\">0.332045</td><td style=\"text-align: right;\">0.110254 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_11           </td><td style=\"text-align: right;\">0.909856</td><td style=\"text-align: right;\"> 0.431777</td><td style=\"text-align: right;\">0.882765</td><td style=\"text-align: right;\">              0.141425</td><td style=\"text-align: right;\">0.3405  </td><td style=\"text-align: right;\">0.11594  </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_6            </td><td style=\"text-align: right;\">0.909728</td><td style=\"text-align: right;\"> 0.464705</td><td style=\"text-align: right;\">0.905746</td><td style=\"text-align: right;\">              0.153377</td><td style=\"text-align: right;\">0.350956</td><td style=\"text-align: right;\">0.12317  </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_48           </td><td style=\"text-align: right;\">0.909668</td><td style=\"text-align: right;\"> 0.432809</td><td style=\"text-align: right;\">0.89251 </td><td style=\"text-align: right;\">              0.148904</td><td style=\"text-align: right;\">0.34068 </td><td style=\"text-align: right;\">0.116063 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_34                    </td><td style=\"text-align: right;\">0.909638</td><td style=\"text-align: right;\"> 0.382438</td><td style=\"text-align: right;\">0.906971</td><td style=\"text-align: right;\">              0.145634</td><td style=\"text-align: right;\">0.342081</td><td style=\"text-align: right;\">0.117019 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_14                </td><td style=\"text-align: right;\">0.909631</td><td style=\"text-align: right;\"> 0.360978</td><td style=\"text-align: right;\">0.877561</td><td style=\"text-align: right;\">              0.125707</td><td style=\"text-align: right;\">0.325205</td><td style=\"text-align: right;\">0.105758 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_94                    </td><td style=\"text-align: right;\">0.909608</td><td style=\"text-align: right;\"> 0.361747</td><td style=\"text-align: right;\">0.877558</td><td style=\"text-align: right;\">              0.130322</td><td style=\"text-align: right;\">0.325317</td><td style=\"text-align: right;\">0.105831 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_58                    </td><td style=\"text-align: right;\">0.909526</td><td style=\"text-align: right;\"> 0.362884</td><td style=\"text-align: right;\">0.884001</td><td style=\"text-align: right;\">              0.136719</td><td style=\"text-align: right;\">0.327409</td><td style=\"text-align: right;\">0.107197 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_129                   </td><td style=\"text-align: right;\">0.90948 </td><td style=\"text-align: right;\"> 0.383314</td><td style=\"text-align: right;\">0.884435</td><td style=\"text-align: right;\">              0.12851 </td><td style=\"text-align: right;\">0.337082</td><td style=\"text-align: right;\">0.113624 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_50           </td><td style=\"text-align: right;\">0.90933 </td><td style=\"text-align: right;\"> 0.449606</td><td style=\"text-align: right;\">0.888303</td><td style=\"text-align: right;\">              0.137508</td><td style=\"text-align: right;\">0.350652</td><td style=\"text-align: right;\">0.122957 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_18                    </td><td style=\"text-align: right;\">0.909157</td><td style=\"text-align: right;\"> 0.368025</td><td style=\"text-align: right;\">0.885938</td><td style=\"text-align: right;\">              0.130322</td><td style=\"text-align: right;\">0.32891 </td><td style=\"text-align: right;\">0.108182 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_33                </td><td style=\"text-align: right;\">0.908548</td><td style=\"text-align: right;\"> 0.372541</td><td style=\"text-align: right;\">0.887952</td><td style=\"text-align: right;\">              0.12591 </td><td style=\"text-align: right;\">0.327954</td><td style=\"text-align: right;\">0.107554 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_19                </td><td style=\"text-align: right;\">0.908488</td><td style=\"text-align: right;\"> 0.368481</td><td style=\"text-align: right;\">0.891333</td><td style=\"text-align: right;\">              0.130525</td><td style=\"text-align: right;\">0.328273</td><td style=\"text-align: right;\">0.107763 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_8                 </td><td style=\"text-align: right;\">0.90821 </td><td style=\"text-align: right;\"> 0.357952</td><td style=\"text-align: right;\">0.87695 </td><td style=\"text-align: right;\">              0.136719</td><td style=\"text-align: right;\">0.323884</td><td style=\"text-align: right;\">0.104901 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_58           </td><td style=\"text-align: right;\">0.90821 </td><td style=\"text-align: right;\"> 0.447846</td><td style=\"text-align: right;\">0.876883</td><td style=\"text-align: right;\">              0.137245</td><td style=\"text-align: right;\">0.331065</td><td style=\"text-align: right;\">0.109604 </td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_5_AutoML_1_20220506_142744            </td><td style=\"text-align: right;\">0.908172</td><td style=\"text-align: right;\"> 0.397645</td><td style=\"text-align: right;\">0.884981</td><td style=\"text-align: right;\">              0.137538</td><td style=\"text-align: right;\">0.332658</td><td style=\"text-align: right;\">0.110662 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_11           </td><td style=\"text-align: right;\">0.908142</td><td style=\"text-align: right;\"> 0.419039</td><td style=\"text-align: right;\">0.892502</td><td style=\"text-align: right;\">              0.142184</td><td style=\"text-align: right;\">0.344716</td><td style=\"text-align: right;\">0.118829 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_15                    </td><td style=\"text-align: right;\">0.908075</td><td style=\"text-align: right;\"> 0.372717</td><td style=\"text-align: right;\">0.868614</td><td style=\"text-align: right;\">              0.128014</td><td style=\"text-align: right;\">0.33161 </td><td style=\"text-align: right;\">0.109965 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_6_AutoML_1_20220506_142744         </td><td style=\"text-align: right;\">0.908052</td><td style=\"text-align: right;\"> 0.381156</td><td style=\"text-align: right;\">0.899801</td><td style=\"text-align: right;\">              0.133945</td><td style=\"text-align: right;\">0.330723</td><td style=\"text-align: right;\">0.109378 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_115                   </td><td style=\"text-align: right;\">0.908022</td><td style=\"text-align: right;\"> 0.363086</td><td style=\"text-align: right;\">0.880698</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.327005</td><td style=\"text-align: right;\">0.106932 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_28                </td><td style=\"text-align: right;\">0.907864</td><td style=\"text-align: right;\"> 0.360626</td><td style=\"text-align: right;\">0.870029</td><td style=\"text-align: right;\">              0.128277</td><td style=\"text-align: right;\">0.324968</td><td style=\"text-align: right;\">0.105604 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_29           </td><td style=\"text-align: right;\">0.907744</td><td style=\"text-align: right;\"> 0.461676</td><td style=\"text-align: right;\">0.882552</td><td style=\"text-align: right;\">              0.145544</td><td style=\"text-align: right;\">0.343067</td><td style=\"text-align: right;\">0.117695 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_28                    </td><td style=\"text-align: right;\">0.907609</td><td style=\"text-align: right;\"> 0.382173</td><td style=\"text-align: right;\">0.884851</td><td style=\"text-align: right;\">              0.13605 </td><td style=\"text-align: right;\">0.337439</td><td style=\"text-align: right;\">0.113865 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_76                    </td><td style=\"text-align: right;\">0.907564</td><td style=\"text-align: right;\"> 0.381808</td><td style=\"text-align: right;\">0.888011</td><td style=\"text-align: right;\">              0.139936</td><td style=\"text-align: right;\">0.340175</td><td style=\"text-align: right;\">0.115719 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_7            </td><td style=\"text-align: right;\">0.907481</td><td style=\"text-align: right;\"> 0.409552</td><td style=\"text-align: right;\">0.888818</td><td style=\"text-align: right;\">              0.145018</td><td style=\"text-align: right;\">0.342203</td><td style=\"text-align: right;\">0.117103 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_90                    </td><td style=\"text-align: right;\">0.907331</td><td style=\"text-align: right;\"> 0.385619</td><td style=\"text-align: right;\">0.875991</td><td style=\"text-align: right;\">              0.127488</td><td style=\"text-align: right;\">0.338514</td><td style=\"text-align: right;\">0.114592 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_19                    </td><td style=\"text-align: right;\">0.907128</td><td style=\"text-align: right;\"> 0.36888 </td><td style=\"text-align: right;\">0.879412</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.329791</td><td style=\"text-align: right;\">0.108762 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_18                </td><td style=\"text-align: right;\">0.907083</td><td style=\"text-align: right;\"> 0.369264</td><td style=\"text-align: right;\">0.881139</td><td style=\"text-align: right;\">              0.143469</td><td style=\"text-align: right;\">0.330431</td><td style=\"text-align: right;\">0.109184 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_12           </td><td style=\"text-align: right;\">0.906872</td><td style=\"text-align: right;\"> 0.419749</td><td style=\"text-align: right;\">0.875123</td><td style=\"text-align: right;\">              0.134118</td><td style=\"text-align: right;\">0.335689</td><td style=\"text-align: right;\">0.112687 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_26                </td><td style=\"text-align: right;\">0.906872</td><td style=\"text-align: right;\"> 0.377388</td><td style=\"text-align: right;\">0.882563</td><td style=\"text-align: right;\">              0.138034</td><td style=\"text-align: right;\">0.331293</td><td style=\"text-align: right;\">0.109755 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_36                </td><td style=\"text-align: right;\">0.906684</td><td style=\"text-align: right;\"> 0.369653</td><td style=\"text-align: right;\">0.869562</td><td style=\"text-align: right;\">              0.134907</td><td style=\"text-align: right;\">0.328992</td><td style=\"text-align: right;\">0.108236 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_11                </td><td style=\"text-align: right;\">0.906669</td><td style=\"text-align: right;\"> 0.365944</td><td style=\"text-align: right;\">0.885376</td><td style=\"text-align: right;\">              0.133622</td><td style=\"text-align: right;\">0.327399</td><td style=\"text-align: right;\">0.10719  </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_23                </td><td style=\"text-align: right;\">0.906444</td><td style=\"text-align: right;\"> 0.360805</td><td style=\"text-align: right;\">0.874756</td><td style=\"text-align: right;\">              0.134907</td><td style=\"text-align: right;\">0.325077</td><td style=\"text-align: right;\">0.105675 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_56           </td><td style=\"text-align: right;\">0.906293</td><td style=\"text-align: right;\"> 0.472084</td><td style=\"text-align: right;\">0.865366</td><td style=\"text-align: right;\">              0.141395</td><td style=\"text-align: right;\">0.337675</td><td style=\"text-align: right;\">0.114024 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_25                </td><td style=\"text-align: right;\">0.906263</td><td style=\"text-align: right;\"> 0.367696</td><td style=\"text-align: right;\">0.858283</td><td style=\"text-align: right;\">              0.136719</td><td style=\"text-align: right;\">0.327862</td><td style=\"text-align: right;\">0.107494 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_83                    </td><td style=\"text-align: right;\">0.90612 </td><td style=\"text-align: right;\"> 0.374731</td><td style=\"text-align: right;\">0.878462</td><td style=\"text-align: right;\">              0.127488</td><td style=\"text-align: right;\">0.332688</td><td style=\"text-align: right;\">0.110681 </td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_1_20220506_142744                              </td><td style=\"text-align: right;\">0.906045</td><td style=\"text-align: right;\"> 0.374304</td><td style=\"text-align: right;\">0.873919</td><td style=\"text-align: right;\">              0.132164</td><td style=\"text-align: right;\">0.332493</td><td style=\"text-align: right;\">0.110551 </td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20220506_142744                                  </td><td style=\"text-align: right;\">0.905767</td><td style=\"text-align: right;\"> 0.37421 </td><td style=\"text-align: right;\">0.85961 </td><td style=\"text-align: right;\">              0.13517 </td><td style=\"text-align: right;\">0.332935</td><td style=\"text-align: right;\">0.110846 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_40                </td><td style=\"text-align: right;\">0.905767</td><td style=\"text-align: right;\"> 0.373831</td><td style=\"text-align: right;\">0.884266</td><td style=\"text-align: right;\">              0.126406</td><td style=\"text-align: right;\">0.331069</td><td style=\"text-align: right;\">0.109607 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_14                    </td><td style=\"text-align: right;\">0.905609</td><td style=\"text-align: right;\"> 0.384517</td><td style=\"text-align: right;\">0.867956</td><td style=\"text-align: right;\">              0.137305</td><td style=\"text-align: right;\">0.337973</td><td style=\"text-align: right;\">0.114226 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_18           </td><td style=\"text-align: right;\">0.905602</td><td style=\"text-align: right;\"> 0.433359</td><td style=\"text-align: right;\">0.897965</td><td style=\"text-align: right;\">              0.152031</td><td style=\"text-align: right;\">0.347305</td><td style=\"text-align: right;\">0.12062  </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_7            </td><td style=\"text-align: right;\">0.905346</td><td style=\"text-align: right;\"> 0.396898</td><td style=\"text-align: right;\">0.872036</td><td style=\"text-align: right;\">              0.141395</td><td style=\"text-align: right;\">0.349028</td><td style=\"text-align: right;\">0.12182  </td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_4_AutoML_1_20220506_142744            </td><td style=\"text-align: right;\">0.905008</td><td style=\"text-align: right;\"> 0.401919</td><td style=\"text-align: right;\">0.891522</td><td style=\"text-align: right;\">              0.140898</td><td style=\"text-align: right;\">0.350476</td><td style=\"text-align: right;\">0.122834 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_24                </td><td style=\"text-align: right;\">0.904745</td><td style=\"text-align: right;\"> 0.369986</td><td style=\"text-align: right;\">0.869801</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.329377</td><td style=\"text-align: right;\">0.108489 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_16                </td><td style=\"text-align: right;\">0.90473 </td><td style=\"text-align: right;\"> 0.360977</td><td style=\"text-align: right;\">0.857966</td><td style=\"text-align: right;\">              0.137245</td><td style=\"text-align: right;\">0.326315</td><td style=\"text-align: right;\">0.106482 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_23           </td><td style=\"text-align: right;\">0.904624</td><td style=\"text-align: right;\"> 0.472512</td><td style=\"text-align: right;\">0.880854</td><td style=\"text-align: right;\">              0.140342</td><td style=\"text-align: right;\">0.342892</td><td style=\"text-align: right;\">0.117575 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_31                    </td><td style=\"text-align: right;\">0.904309</td><td style=\"text-align: right;\"> 0.388311</td><td style=\"text-align: right;\">0.872255</td><td style=\"text-align: right;\">              0.129037</td><td style=\"text-align: right;\">0.339469</td><td style=\"text-align: right;\">0.115239 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_109                   </td><td style=\"text-align: right;\">0.904294</td><td style=\"text-align: right;\"> 0.386182</td><td style=\"text-align: right;\">0.870745</td><td style=\"text-align: right;\">              0.137245</td><td style=\"text-align: right;\">0.338371</td><td style=\"text-align: right;\">0.114495 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_37                </td><td style=\"text-align: right;\">0.904279</td><td style=\"text-align: right;\"> 0.384295</td><td style=\"text-align: right;\">0.866202</td><td style=\"text-align: right;\">              0.136982</td><td style=\"text-align: right;\">0.336759</td><td style=\"text-align: right;\">0.113407 </td></tr>\n",
       "<tr><td>StackedEnsemble_Best1000_1_AutoML_1_20220506_142744             </td><td style=\"text-align: right;\">0.904249</td><td style=\"text-align: right;\"> 0.402056</td><td style=\"text-align: right;\">0.889169</td><td style=\"text-align: right;\">              0.145341</td><td style=\"text-align: right;\">0.350696</td><td style=\"text-align: right;\">0.122988 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_121                   </td><td style=\"text-align: right;\">0.903813</td><td style=\"text-align: right;\"> 0.375909</td><td style=\"text-align: right;\">0.862057</td><td style=\"text-align: right;\">              0.131111</td><td style=\"text-align: right;\">0.332945</td><td style=\"text-align: right;\">0.110852 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_3            </td><td style=\"text-align: right;\">0.90364 </td><td style=\"text-align: right;\"> 0.394557</td><td style=\"text-align: right;\">0.874146</td><td style=\"text-align: right;\">              0.167283</td><td style=\"text-align: right;\">0.34787 </td><td style=\"text-align: right;\">0.121014 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_2            </td><td style=\"text-align: right;\">0.903534</td><td style=\"text-align: right;\"> 0.474202</td><td style=\"text-align: right;\">0.900291</td><td style=\"text-align: right;\">              0.160563</td><td style=\"text-align: right;\">0.346234</td><td style=\"text-align: right;\">0.119878 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_5            </td><td style=\"text-align: right;\">0.903392</td><td style=\"text-align: right;\"> 0.417007</td><td style=\"text-align: right;\">0.87351 </td><td style=\"text-align: right;\">              0.156413</td><td style=\"text-align: right;\">0.342832</td><td style=\"text-align: right;\">0.117534 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_41           </td><td style=\"text-align: right;\">0.903249</td><td style=\"text-align: right;\"> 0.482219</td><td style=\"text-align: right;\">0.872844</td><td style=\"text-align: right;\">              0.154399</td><td style=\"text-align: right;\">0.363755</td><td style=\"text-align: right;\">0.132317 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_46           </td><td style=\"text-align: right;\">0.903241</td><td style=\"text-align: right;\"> 0.480305</td><td style=\"text-align: right;\">0.86105 </td><td style=\"text-align: right;\">              0.134968</td><td style=\"text-align: right;\">0.344652</td><td style=\"text-align: right;\">0.118785 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_9                     </td><td style=\"text-align: right;\">0.903189</td><td style=\"text-align: right;\"> 0.394759</td><td style=\"text-align: right;\">0.899082</td><td style=\"text-align: right;\">              0.164246</td><td style=\"text-align: right;\">0.348225</td><td style=\"text-align: right;\">0.121261 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_2            </td><td style=\"text-align: right;\">0.902843</td><td style=\"text-align: right;\"> 0.467873</td><td style=\"text-align: right;\">0.872925</td><td style=\"text-align: right;\">              0.137801</td><td style=\"text-align: right;\">0.349925</td><td style=\"text-align: right;\">0.122448 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_39                </td><td style=\"text-align: right;\">0.90273 </td><td style=\"text-align: right;\"> 0.363035</td><td style=\"text-align: right;\">0.860049</td><td style=\"text-align: right;\">              0.137245</td><td style=\"text-align: right;\">0.326953</td><td style=\"text-align: right;\">0.106898 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_41                    </td><td style=\"text-align: right;\">0.9027  </td><td style=\"text-align: right;\"> 0.401154</td><td style=\"text-align: right;\">0.887962</td><td style=\"text-align: right;\">              0.14277 </td><td style=\"text-align: right;\">0.347572</td><td style=\"text-align: right;\">0.120806 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_2                     </td><td style=\"text-align: right;\">0.902587</td><td style=\"text-align: right;\"> 0.378044</td><td style=\"text-align: right;\">0.852358</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.333999</td><td style=\"text-align: right;\">0.111555 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_9            </td><td style=\"text-align: right;\">0.902384</td><td style=\"text-align: right;\"> 0.414099</td><td style=\"text-align: right;\">0.878809</td><td style=\"text-align: right;\">              0.147972</td><td style=\"text-align: right;\">0.347859</td><td style=\"text-align: right;\">0.121006 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_30           </td><td style=\"text-align: right;\">0.902317</td><td style=\"text-align: right;\"> 0.480177</td><td style=\"text-align: right;\">0.860131</td><td style=\"text-align: right;\">              0.155887</td><td style=\"text-align: right;\">0.36175 </td><td style=\"text-align: right;\">0.130863 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_75                    </td><td style=\"text-align: right;\">0.902129</td><td style=\"text-align: right;\"> 0.40539 </td><td style=\"text-align: right;\">0.861304</td><td style=\"text-align: right;\">              0.134471</td><td style=\"text-align: right;\">0.348733</td><td style=\"text-align: right;\">0.121615 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_31                </td><td style=\"text-align: right;\">0.902024</td><td style=\"text-align: right;\"> 0.373613</td><td style=\"text-align: right;\">0.864629</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.331478</td><td style=\"text-align: right;\">0.109877 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_39           </td><td style=\"text-align: right;\">0.901903</td><td style=\"text-align: right;\"> 0.423681</td><td style=\"text-align: right;\">0.884849</td><td style=\"text-align: right;\">              0.163427</td><td style=\"text-align: right;\">0.349016</td><td style=\"text-align: right;\">0.121812 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_38                </td><td style=\"text-align: right;\">0.901813</td><td style=\"text-align: right;\"> 0.387318</td><td style=\"text-align: right;\">0.862378</td><td style=\"text-align: right;\">              0.142154</td><td style=\"text-align: right;\">0.339135</td><td style=\"text-align: right;\">0.115013 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_34                </td><td style=\"text-align: right;\">0.901783</td><td style=\"text-align: right;\"> 0.374815</td><td style=\"text-align: right;\">0.869693</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.331836</td><td style=\"text-align: right;\">0.110115 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_12                </td><td style=\"text-align: right;\">0.901738</td><td style=\"text-align: right;\"> 0.367606</td><td style=\"text-align: right;\">0.868852</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.328655</td><td style=\"text-align: right;\">0.108014 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_96                    </td><td style=\"text-align: right;\">0.9017  </td><td style=\"text-align: right;\"> 0.376409</td><td style=\"text-align: right;\">0.868003</td><td style=\"text-align: right;\">              0.137245</td><td style=\"text-align: right;\">0.333561</td><td style=\"text-align: right;\">0.111263 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_23                    </td><td style=\"text-align: right;\">0.90167 </td><td style=\"text-align: right;\"> 0.403463</td><td style=\"text-align: right;\">0.879137</td><td style=\"text-align: right;\">              0.131638</td><td style=\"text-align: right;\">0.347668</td><td style=\"text-align: right;\">0.120873 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_85                    </td><td style=\"text-align: right;\">0.901603</td><td style=\"text-align: right;\"> 0.418017</td><td style=\"text-align: right;\">0.893171</td><td style=\"text-align: right;\">              0.158518</td><td style=\"text-align: right;\">0.357959</td><td style=\"text-align: right;\">0.128135 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_18           </td><td style=\"text-align: right;\">0.90152 </td><td style=\"text-align: right;\"> 0.482902</td><td style=\"text-align: right;\">0.869049</td><td style=\"text-align: right;\">              0.153316</td><td style=\"text-align: right;\">0.35372 </td><td style=\"text-align: right;\">0.125118 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_38           </td><td style=\"text-align: right;\">0.901302</td><td style=\"text-align: right;\"> 0.488962</td><td style=\"text-align: right;\">0.863893</td><td style=\"text-align: right;\">              0.14268 </td><td style=\"text-align: right;\">0.349749</td><td style=\"text-align: right;\">0.122325 </td></tr>\n",
       "<tr><td>GBM_1_AutoML_1_20220506_142744                                  </td><td style=\"text-align: right;\">0.901234</td><td style=\"text-align: right;\"> 0.374838</td><td style=\"text-align: right;\">0.861538</td><td style=\"text-align: right;\">              0.130525</td><td style=\"text-align: right;\">0.332513</td><td style=\"text-align: right;\">0.110565 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_57                    </td><td style=\"text-align: right;\">0.901227</td><td style=\"text-align: right;\"> 0.376046</td><td style=\"text-align: right;\">0.852446</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.333054</td><td style=\"text-align: right;\">0.110925 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_20           </td><td style=\"text-align: right;\">0.901091</td><td style=\"text-align: right;\"> 0.461774</td><td style=\"text-align: right;\">0.873687</td><td style=\"text-align: right;\">              0.138065</td><td style=\"text-align: right;\">0.347016</td><td style=\"text-align: right;\">0.12042  </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_16                    </td><td style=\"text-align: right;\">0.901054</td><td style=\"text-align: right;\"> 0.375289</td><td style=\"text-align: right;\">0.869941</td><td style=\"text-align: right;\">              0.133096</td><td style=\"text-align: right;\">0.332934</td><td style=\"text-align: right;\">0.110845 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_6            </td><td style=\"text-align: right;\">0.900813</td><td style=\"text-align: right;\"> 0.469483</td><td style=\"text-align: right;\">0.868939</td><td style=\"text-align: right;\">              0.139846</td><td style=\"text-align: right;\">0.34759 </td><td style=\"text-align: right;\">0.120819 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_13           </td><td style=\"text-align: right;\">0.900723</td><td style=\"text-align: right;\"> 0.723637</td><td style=\"text-align: right;\">0.88836 </td><td style=\"text-align: right;\">              0.161615</td><td style=\"text-align: right;\">0.368761</td><td style=\"text-align: right;\">0.135985 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_99                    </td><td style=\"text-align: right;\">0.900686</td><td style=\"text-align: right;\"> 0.37732 </td><td style=\"text-align: right;\">0.850737</td><td style=\"text-align: right;\">              0.136719</td><td style=\"text-align: right;\">0.334219</td><td style=\"text-align: right;\">0.111702 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_4            </td><td style=\"text-align: right;\">0.900595</td><td style=\"text-align: right;\"> 0.538373</td><td style=\"text-align: right;\">0.852098</td><td style=\"text-align: right;\">              0.148904</td><td style=\"text-align: right;\">0.358299</td><td style=\"text-align: right;\">0.128378 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_40           </td><td style=\"text-align: right;\">0.900468</td><td style=\"text-align: right;\"> 0.504124</td><td style=\"text-align: right;\">0.880658</td><td style=\"text-align: right;\">              0.136719</td><td style=\"text-align: right;\">0.34761 </td><td style=\"text-align: right;\">0.120833 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_19           </td><td style=\"text-align: right;\">0.900114</td><td style=\"text-align: right;\"> 0.425499</td><td style=\"text-align: right;\">0.879134</td><td style=\"text-align: right;\">              0.141658</td><td style=\"text-align: right;\">0.346597</td><td style=\"text-align: right;\">0.12013  </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_8            </td><td style=\"text-align: right;\">0.899994</td><td style=\"text-align: right;\"> 0.42326 </td><td style=\"text-align: right;\">0.872571</td><td style=\"text-align: right;\">              0.162638</td><td style=\"text-align: right;\">0.352553</td><td style=\"text-align: right;\">0.124293 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_17                </td><td style=\"text-align: right;\">0.899889</td><td style=\"text-align: right;\"> 0.403356</td><td style=\"text-align: right;\">0.873916</td><td style=\"text-align: right;\">              0.142154</td><td style=\"text-align: right;\">0.347042</td><td style=\"text-align: right;\">0.120438 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_52                    </td><td style=\"text-align: right;\">0.899678</td><td style=\"text-align: right;\"> 0.381931</td><td style=\"text-align: right;\">0.849262</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.336437</td><td style=\"text-align: right;\">0.11319  </td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20220506_142744                                  </td><td style=\"text-align: right;\">0.899596</td><td style=\"text-align: right;\"> 0.434268</td><td style=\"text-align: right;\">0.876317</td><td style=\"text-align: right;\">              0.155188</td><td style=\"text-align: right;\">0.365085</td><td style=\"text-align: right;\">0.133287 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_13           </td><td style=\"text-align: right;\">0.899197</td><td style=\"text-align: right;\"> 0.489654</td><td style=\"text-align: right;\">0.851703</td><td style=\"text-align: right;\">              0.152294</td><td style=\"text-align: right;\">0.360774</td><td style=\"text-align: right;\">0.130158 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_32                </td><td style=\"text-align: right;\">0.899122</td><td style=\"text-align: right;\"> 0.374158</td><td style=\"text-align: right;\">0.851773</td><td style=\"text-align: right;\">              0.13517 </td><td style=\"text-align: right;\">0.331298</td><td style=\"text-align: right;\">0.109758 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_47           </td><td style=\"text-align: right;\">0.899084</td><td style=\"text-align: right;\"> 0.476346</td><td style=\"text-align: right;\">0.879889</td><td style=\"text-align: right;\">              0.144582</td><td style=\"text-align: right;\">0.345862</td><td style=\"text-align: right;\">0.11962  </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20220506_142744         </td><td style=\"text-align: right;\">0.898761</td><td style=\"text-align: right;\"> 0.379116</td><td style=\"text-align: right;\">0.847672</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.333198</td><td style=\"text-align: right;\">0.111021 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_2            </td><td style=\"text-align: right;\">0.898761</td><td style=\"text-align: right;\"> 0.646924</td><td style=\"text-align: right;\">0.854167</td><td style=\"text-align: right;\">              0.165968</td><td style=\"text-align: right;\">0.369843</td><td style=\"text-align: right;\">0.136783 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_15           </td><td style=\"text-align: right;\">0.898521</td><td style=\"text-align: right;\"> 1.18022 </td><td style=\"text-align: right;\">0.884452</td><td style=\"text-align: right;\">              0.15358 </td><td style=\"text-align: right;\">0.38027 </td><td style=\"text-align: right;\">0.144605 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_14           </td><td style=\"text-align: right;\">0.897619</td><td style=\"text-align: right;\"> 0.783424</td><td style=\"text-align: right;\">0.876101</td><td style=\"text-align: right;\">              0.154895</td><td style=\"text-align: right;\">0.374424</td><td style=\"text-align: right;\">0.140194 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_6                     </td><td style=\"text-align: right;\">0.89622 </td><td style=\"text-align: right;\"> 0.377219</td><td style=\"text-align: right;\">0.858053</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.333956</td><td style=\"text-align: right;\">0.111527 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_25                    </td><td style=\"text-align: right;\">0.895777</td><td style=\"text-align: right;\"> 0.379336</td><td style=\"text-align: right;\">0.846243</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.335181</td><td style=\"text-align: right;\">0.112346 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_36           </td><td style=\"text-align: right;\">0.895063</td><td style=\"text-align: right;\"> 0.521354</td><td style=\"text-align: right;\">0.842432</td><td style=\"text-align: right;\">              0.143499</td><td style=\"text-align: right;\">0.358378</td><td style=\"text-align: right;\">0.128435 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_5            </td><td style=\"text-align: right;\">0.894627</td><td style=\"text-align: right;\"> 0.446933</td><td style=\"text-align: right;\">0.875805</td><td style=\"text-align: right;\">              0.158022</td><td style=\"text-align: right;\">0.362517</td><td style=\"text-align: right;\">0.131418 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220506_142744_model_13                </td><td style=\"text-align: right;\">0.894056</td><td style=\"text-align: right;\"> 0.386187</td><td style=\"text-align: right;\">0.857306</td><td style=\"text-align: right;\">              0.138531</td><td style=\"text-align: right;\">0.337665</td><td style=\"text-align: right;\">0.114018 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_43           </td><td style=\"text-align: right;\">0.892282</td><td style=\"text-align: right;\"> 0.463053</td><td style=\"text-align: right;\">0.848896</td><td style=\"text-align: right;\">              0.166231</td><td style=\"text-align: right;\">0.359999</td><td style=\"text-align: right;\">0.129599 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_15           </td><td style=\"text-align: right;\">0.892221</td><td style=\"text-align: right;\"> 0.461006</td><td style=\"text-align: right;\">0.850242</td><td style=\"text-align: right;\">              0.151505</td><td style=\"text-align: right;\">0.354774</td><td style=\"text-align: right;\">0.125864 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_54           </td><td style=\"text-align: right;\">0.892124</td><td style=\"text-align: right;\"> 0.594987</td><td style=\"text-align: right;\">0.866434</td><td style=\"text-align: right;\">              0.154602</td><td style=\"text-align: right;\">0.36432 </td><td style=\"text-align: right;\">0.132729 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_51           </td><td style=\"text-align: right;\">0.891808</td><td style=\"text-align: right;\"> 0.50964 </td><td style=\"text-align: right;\">0.865104</td><td style=\"text-align: right;\">              0.143469</td><td style=\"text-align: right;\">0.361866</td><td style=\"text-align: right;\">0.130947 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_37           </td><td style=\"text-align: right;\">0.890432</td><td style=\"text-align: right;\"> 0.53025 </td><td style=\"text-align: right;\">0.869007</td><td style=\"text-align: right;\">              0.165035</td><td style=\"text-align: right;\">0.369376</td><td style=\"text-align: right;\">0.136439 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_5            </td><td style=\"text-align: right;\">0.887606</td><td style=\"text-align: right;\"> 0.501704</td><td style=\"text-align: right;\">0.845865</td><td style=\"text-align: right;\">              0.153873</td><td style=\"text-align: right;\">0.363527</td><td style=\"text-align: right;\">0.132152 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_17           </td><td style=\"text-align: right;\">0.886742</td><td style=\"text-align: right;\"> 0.612442</td><td style=\"text-align: right;\">0.849197</td><td style=\"text-align: right;\">              0.171463</td><td style=\"text-align: right;\">0.397227</td><td style=\"text-align: right;\">0.157789 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_27           </td><td style=\"text-align: right;\">0.886681</td><td style=\"text-align: right;\"> 0.497868</td><td style=\"text-align: right;\">0.851014</td><td style=\"text-align: right;\">              0.187474</td><td style=\"text-align: right;\">0.373798</td><td style=\"text-align: right;\">0.139725 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_1            </td><td style=\"text-align: right;\">0.886591</td><td style=\"text-align: right;\"> 0.605091</td><td style=\"text-align: right;\">0.84877 </td><td style=\"text-align: right;\">              0.145311</td><td style=\"text-align: right;\">0.354889</td><td style=\"text-align: right;\">0.125946 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_52           </td><td style=\"text-align: right;\">0.886366</td><td style=\"text-align: right;\"> 0.529299</td><td style=\"text-align: right;\">0.834112</td><td style=\"text-align: right;\">              0.162141</td><td style=\"text-align: right;\">0.367601</td><td style=\"text-align: right;\">0.13513  </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_55           </td><td style=\"text-align: right;\">0.885667</td><td style=\"text-align: right;\"> 0.505706</td><td style=\"text-align: right;\">0.854914</td><td style=\"text-align: right;\">              0.165998</td><td style=\"text-align: right;\">0.371122</td><td style=\"text-align: right;\">0.137731 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_11           </td><td style=\"text-align: right;\">0.885629</td><td style=\"text-align: right;\"> 0.693227</td><td style=\"text-align: right;\">0.854031</td><td style=\"text-align: right;\">              0.166321</td><td style=\"text-align: right;\">0.403358</td><td style=\"text-align: right;\">0.162698 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_14           </td><td style=\"text-align: right;\">0.885434</td><td style=\"text-align: right;\"> 0.624017</td><td style=\"text-align: right;\">0.849538</td><td style=\"text-align: right;\">              0.164742</td><td style=\"text-align: right;\">0.373178</td><td style=\"text-align: right;\">0.139262 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_28           </td><td style=\"text-align: right;\">0.88493 </td><td style=\"text-align: right;\"> 0.497563</td><td style=\"text-align: right;\">0.866034</td><td style=\"text-align: right;\">              0.176897</td><td style=\"text-align: right;\">0.382064</td><td style=\"text-align: right;\">0.145973 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_8            </td><td style=\"text-align: right;\">0.884674</td><td style=\"text-align: right;\"> 0.445519</td><td style=\"text-align: right;\">0.853728</td><td style=\"text-align: right;\">              0.18049 </td><td style=\"text-align: right;\">0.365167</td><td style=\"text-align: right;\">0.133347 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_34           </td><td style=\"text-align: right;\">0.881668</td><td style=\"text-align: right;\"> 0.617926</td><td style=\"text-align: right;\">0.827008</td><td style=\"text-align: right;\">              0.169651</td><td style=\"text-align: right;\">0.385152</td><td style=\"text-align: right;\">0.148342 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_35           </td><td style=\"text-align: right;\">0.881021</td><td style=\"text-align: right;\"> 0.712039</td><td style=\"text-align: right;\">0.836232</td><td style=\"text-align: right;\">              0.158285</td><td style=\"text-align: right;\">0.374552</td><td style=\"text-align: right;\">0.140289 </td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20220506_142744                         </td><td style=\"text-align: right;\">0.879863</td><td style=\"text-align: right;\"> 0.458415</td><td style=\"text-align: right;\">0.831234</td><td style=\"text-align: right;\">              0.163164</td><td style=\"text-align: right;\">0.363212</td><td style=\"text-align: right;\">0.131923 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220506_142744_model_16           </td><td style=\"text-align: right;\">0.879488</td><td style=\"text-align: right;\"> 0.513243</td><td style=\"text-align: right;\">0.849786</td><td style=\"text-align: right;\">              0.175086</td><td style=\"text-align: right;\">0.376292</td><td style=\"text-align: right;\">0.141596 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220506_142744_model_132                   </td><td style=\"text-align: right;\">0.878556</td><td style=\"text-align: right;\"> 0.623474</td><td style=\"text-align: right;\">0.841241</td><td style=\"text-align: right;\">              0.142507</td><td style=\"text-align: right;\">0.464167</td><td style=\"text-align: right;\">0.215451 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_12           </td><td style=\"text-align: right;\">0.867491</td><td style=\"text-align: right;\"> 1.97748 </td><td style=\"text-align: right;\">0.82965 </td><td style=\"text-align: right;\">              0.168366</td><td style=\"text-align: right;\">0.389373</td><td style=\"text-align: right;\">0.151611 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_4            </td><td style=\"text-align: right;\">0.861665</td><td style=\"text-align: right;\"> 0.639743</td><td style=\"text-align: right;\">0.836026</td><td style=\"text-align: right;\">              0.192706</td><td style=\"text-align: right;\">0.396071</td><td style=\"text-align: right;\">0.156872 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_14           </td><td style=\"text-align: right;\">0.861605</td><td style=\"text-align: right;\"> 0.862144</td><td style=\"text-align: right;\">0.824294</td><td style=\"text-align: right;\">              0.205327</td><td style=\"text-align: right;\">0.406033</td><td style=\"text-align: right;\">0.164863 </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220506_142744_model_15           </td><td style=\"text-align: right;\">0.859365</td><td style=\"text-align: right;\"> 0.55812 </td><td style=\"text-align: right;\">0.853655</td><td style=\"text-align: right;\">              0.214182</td><td style=\"text-align: right;\">0.404615</td><td style=\"text-align: right;\">0.163713 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220506_142744_model_6            </td><td style=\"text-align: right;\">0.832018</td><td style=\"text-align: right;\"> 0.819576</td><td style=\"text-align: right;\">0.810864</td><td style=\"text-align: right;\">              0.234109</td><td style=\"text-align: right;\">0.441607</td><td style=\"text-align: right;\">0.195017 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tm5_3CBwyetw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "H20AutoMLAirlines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "idlsvenv",
   "language": "python",
   "name": "idlsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
