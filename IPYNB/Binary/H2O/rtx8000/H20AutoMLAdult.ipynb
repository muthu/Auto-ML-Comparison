{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tk34b2C7bI-i",
    "outputId": "9866df90-d4c6-4c6c-e88e-39b1d441345a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting h2o\n",
      "  Downloading h2o-3.36.1.1.tar.gz (177.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 177.0 MB 131.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from h2o) (2.24.0)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 91.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->h2o) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->h2o) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->h2o) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->h2o) (2020.6.20)\n",
      "Building wheels for collected packages: h2o, future\n",
      "  Building wheel for h2o (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for h2o: filename=h2o-3.36.1.1-py2.py3-none-any.whl size=177068062 sha256=0533030546660b1c148809ab4577dcff647b0b881df5f2d4b3bf02c973cf12d2\n",
      "  Stored in directory: /home/mk7516/.cache/pip/wheels/bf/d7/e0/905f059465fafaf07c9e79ba4c8d642ac646b01ea8c38b07d5\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=4f831c65e1c94dc6bcb6bd66006a00f5a1ba67ae0b30925cbe353bfd64aac98a\n",
      "  Stored in directory: /home/mk7516/.cache/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built h2o future\n",
      "Installing collected packages: tabulate, future, h2o\n",
      "Successfully installed future-0.18.2 h2o-3.36.1.1 tabulate-0.8.9\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kCgyhMjHJB6Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk7516/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/mk7516/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/mk7516/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/mk7516/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "cNn--_UnbWd-",
    "outputId": "274afb96-bd18-492e-e8a6-5be73eb680d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_312-debug\"; OpenJDK Runtime Environment (build 1.8.0_312-debug-b07); OpenJDK 64-Bit Server VM (build 25.312-b07-debug, mixed mode)\n",
      "  Starting server from /home/mk7516/.local/lib/python3.8/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /state/partition1/job-18891165/tmpdlqaa_2p\n",
      "  JVM stdout: /state/partition1/job-18891165/tmpdlqaa_2p/h2o_mk7516_started_from_python.out\n",
      "  JVM stderr: /state/partition1/job-18891165/tmpdlqaa_2p/h2o_mk7516_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>06 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.36.1.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>18 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_mk7516_6z0xms</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.541 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         06 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.36.1.1\n",
       "H2O_cluster_version_age:    18 days\n",
       "H2O_cluster_name:           H2O_from_python_mk7516_6z0xms\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.541 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.6 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kdt8Wp7Falm7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def dataSetup(name):\n",
    "  X,y = sklearn.datasets.fetch_openml(name, as_frame=True, return_X_y=True)\n",
    "  train = pd.concat([X, y], axis=1, join='inner')\n",
    "  train.dropna()\n",
    "  train = train.apply(lambda x: pd.factorize(x)[0])\n",
    "  X,y = train.iloc[:,:-1], train.iloc[:, -1]\n",
    "  # X = X.apply(lambda x: pd.factorize(x)[0])\n",
    "  X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y,random_state=42)\n",
    "  y_train = y_train.to_frame(name=\"class\")\n",
    "  y_test = y_test.to_frame(name=\"class\")\n",
    "  test = pd.concat([X_test, y_test], axis=1, join='inner')\n",
    "  train = pd.concat([X_train, y_train], axis=1, join='inner')\n",
    "  test = h2o.H2OFrame(test)\n",
    "  train = h2o.H2OFrame(train)\n",
    "  return (test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gpw9R9koa8kA",
    "outputId": "3d5374f5-b7db-46ec-c5cb-7fc10df849a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk7516/.local/lib/python3.8/site-packages/sklearn/datasets/_openml.py:417: UserWarning: Multiple active versions of the dataset matching the name airlines exist. Versions may be fundamentally different, returning version 1.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "test, train = dataSetup('airlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0LPdFQlbA_5",
    "outputId": "d582af48-65ba-4760-e90b-e936af7442f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404537, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uDeYZ8nTQX-0"
   },
   "outputs": [],
   "source": [
    "x = train.columns\n",
    "y = \"class\"\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "u_ErSp1nU27w"
   },
   "outputs": [],
   "source": [
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1J4XoxvQunQ",
    "outputId": "f116c4e2-0059-4307-f9a4-1c3892867859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_3_AutoML_1_20220501_153607\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.1847787640101926\n",
      "RMSE: 0.42985900480296163\n",
      "LogLoss: 0.5488763137460702\n",
      "Null degrees of freedom: 9936\n",
      "Residual degrees of freedom: 9919\n",
      "Null deviance: 13673.963424813815\n",
      "Residual deviance: 10908.3678593894\n",
      "AIC: 10944.3678593894\n",
      "AUC: 0.7997663560964748\n",
      "AUCPR: 0.8247391427885559\n",
      "Gini: 0.5995327121929497\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4772564283512219: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2395.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>(2070.0/4465.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>725.0</td>\n",
       "      <td>4747.0</td>\n",
       "      <td>0.1325</td>\n",
       "      <td>(725.0/5472.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>6817.0</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>(2795.0/9937.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1   Error              Rate\n",
       "0      0  2395.0  2070.0  0.4636   (2070.0/4465.0)\n",
       "1      1   725.0  4747.0  0.1325    (725.0/5472.0)\n",
       "2  Total  3120.0  6817.0  0.2813   (2795.0/9937.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.477256</td>\n",
       "      <td>0.772561</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.230732</td>\n",
       "      <td>0.873319</td>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.574722</td>\n",
       "      <td>0.759089</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.537781</td>\n",
       "      <td>0.729898</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.959875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.103830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.959875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.565873</td>\n",
       "      <td>0.454590</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.565873</td>\n",
       "      <td>0.727436</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.565873</td>\n",
       "      <td>0.728210</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.959875</td>\n",
       "      <td>4465.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.959875</td>\n",
       "      <td>5471.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.054722</td>\n",
       "      <td>4465.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.103830</td>\n",
       "      <td>5472.000000</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.959875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.959875</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.054722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.103830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.477256     0.772561  234.0\n",
       "1                        max f2   0.230732     0.873319  341.0\n",
       "2                  max f0point5   0.574722     0.759089  178.0\n",
       "3                  max accuracy   0.537781     0.729898  199.0\n",
       "4                 max precision   0.959875     1.000000    0.0\n",
       "5                    max recall   0.103830     1.000000  388.0\n",
       "6               max specificity   0.959875     1.000000    0.0\n",
       "7              max absolute_mcc   0.565873     0.454590  183.0\n",
       "8    max min_per_class_accuracy   0.565873     0.727436  183.0\n",
       "9   max mean_per_class_accuracy   0.565873     0.728210  183.0\n",
       "10                      max tns   0.959875  4465.000000    0.0\n",
       "11                      max fns   0.959875  5471.000000    0.0\n",
       "12                      max fps   0.054722  4465.000000  399.0\n",
       "13                      max tps   0.103830  5472.000000  388.0\n",
       "14                      max tnr   0.959875     1.000000    0.0\n",
       "15                      max fnr   0.959875     0.999817    0.0\n",
       "16                      max fpr   0.054722     1.000000  399.0\n",
       "17                      max tpr   0.103830     1.000000  388.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 55.07 %, avg score: 55.51 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.904416</td>\n",
       "      <td>1.797813</td>\n",
       "      <td>1.797813</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.918861</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.918861</td>\n",
       "      <td>0.018092</td>\n",
       "      <td>0.018092</td>\n",
       "      <td>79.781250</td>\n",
       "      <td>79.781250</td>\n",
       "      <td>0.017868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020026</td>\n",
       "      <td>0.882080</td>\n",
       "      <td>1.779286</td>\n",
       "      <td>1.788596</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.892798</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>0.017727</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>77.928591</td>\n",
       "      <td>78.859576</td>\n",
       "      <td>0.035147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030090</td>\n",
       "      <td>0.868775</td>\n",
       "      <td>1.779653</td>\n",
       "      <td>1.785605</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.875224</td>\n",
       "      <td>0.983278</td>\n",
       "      <td>0.895637</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.053728</td>\n",
       "      <td>77.965278</td>\n",
       "      <td>78.560479</td>\n",
       "      <td>0.052608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040052</td>\n",
       "      <td>0.855016</td>\n",
       "      <td>1.760943</td>\n",
       "      <td>1.779470</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.861853</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.887233</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.071272</td>\n",
       "      <td>76.094276</td>\n",
       "      <td>77.947027</td>\n",
       "      <td>0.069480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050015</td>\n",
       "      <td>0.844864</td>\n",
       "      <td>1.669227</td>\n",
       "      <td>1.757510</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.849855</td>\n",
       "      <td>0.967807</td>\n",
       "      <td>0.879788</td>\n",
       "      <td>0.016630</td>\n",
       "      <td>0.087902</td>\n",
       "      <td>66.922699</td>\n",
       "      <td>75.751034</td>\n",
       "      <td>0.084319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100030</td>\n",
       "      <td>0.801044</td>\n",
       "      <td>1.647894</td>\n",
       "      <td>1.702702</td>\n",
       "      <td>0.907445</td>\n",
       "      <td>0.822436</td>\n",
       "      <td>0.937626</td>\n",
       "      <td>0.851112</td>\n",
       "      <td>0.082420</td>\n",
       "      <td>0.170322</td>\n",
       "      <td>64.789431</td>\n",
       "      <td>70.270233</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150045</td>\n",
       "      <td>0.766324</td>\n",
       "      <td>1.487124</td>\n",
       "      <td>1.630843</td>\n",
       "      <td>0.818913</td>\n",
       "      <td>0.782763</td>\n",
       "      <td>0.898055</td>\n",
       "      <td>0.828329</td>\n",
       "      <td>0.074379</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>48.712413</td>\n",
       "      <td>63.084293</td>\n",
       "      <td>0.210658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200060</td>\n",
       "      <td>0.734445</td>\n",
       "      <td>1.530971</td>\n",
       "      <td>1.605875</td>\n",
       "      <td>0.843058</td>\n",
       "      <td>0.750382</td>\n",
       "      <td>0.884306</td>\n",
       "      <td>0.808842</td>\n",
       "      <td>0.076572</td>\n",
       "      <td>0.321272</td>\n",
       "      <td>53.097055</td>\n",
       "      <td>60.587483</td>\n",
       "      <td>0.269760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.299990</td>\n",
       "      <td>0.679120</td>\n",
       "      <td>1.397183</td>\n",
       "      <td>1.536358</td>\n",
       "      <td>0.769386</td>\n",
       "      <td>0.705591</td>\n",
       "      <td>0.846025</td>\n",
       "      <td>0.774448</td>\n",
       "      <td>0.139620</td>\n",
       "      <td>0.460892</td>\n",
       "      <td>39.718306</td>\n",
       "      <td>53.635758</td>\n",
       "      <td>0.358092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400020</td>\n",
       "      <td>0.628140</td>\n",
       "      <td>1.262411</td>\n",
       "      <td>1.467854</td>\n",
       "      <td>0.695171</td>\n",
       "      <td>0.653904</td>\n",
       "      <td>0.808302</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>0.126279</td>\n",
       "      <td>0.587171</td>\n",
       "      <td>26.241127</td>\n",
       "      <td>46.785377</td>\n",
       "      <td>0.416510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500050</td>\n",
       "      <td>0.577733</td>\n",
       "      <td>1.150968</td>\n",
       "      <td>1.404464</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.603491</td>\n",
       "      <td>0.773395</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.115132</td>\n",
       "      <td>0.702303</td>\n",
       "      <td>15.096831</td>\n",
       "      <td>40.446393</td>\n",
       "      <td>0.450119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.599980</td>\n",
       "      <td>0.525297</td>\n",
       "      <td>0.945476</td>\n",
       "      <td>1.328017</td>\n",
       "      <td>0.520645</td>\n",
       "      <td>0.551709</td>\n",
       "      <td>0.731298</td>\n",
       "      <td>0.688750</td>\n",
       "      <td>0.094481</td>\n",
       "      <td>0.796784</td>\n",
       "      <td>-5.452403</td>\n",
       "      <td>32.801726</td>\n",
       "      <td>0.437993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700010</td>\n",
       "      <td>0.467384</td>\n",
       "      <td>0.792889</td>\n",
       "      <td>1.251548</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.497791</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.661462</td>\n",
       "      <td>0.079313</td>\n",
       "      <td>0.876096</td>\n",
       "      <td>-20.711072</td>\n",
       "      <td>25.154842</td>\n",
       "      <td>0.391886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799940</td>\n",
       "      <td>0.387435</td>\n",
       "      <td>0.599838</td>\n",
       "      <td>1.170136</td>\n",
       "      <td>0.330312</td>\n",
       "      <td>0.429691</td>\n",
       "      <td>0.644358</td>\n",
       "      <td>0.632509</td>\n",
       "      <td>0.059942</td>\n",
       "      <td>0.936038</td>\n",
       "      <td>-40.016225</td>\n",
       "      <td>17.013583</td>\n",
       "      <td>0.302891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899970</td>\n",
       "      <td>0.248567</td>\n",
       "      <td>0.471349</td>\n",
       "      <td>1.092467</td>\n",
       "      <td>0.259557</td>\n",
       "      <td>0.324762</td>\n",
       "      <td>0.601588</td>\n",
       "      <td>0.598303</td>\n",
       "      <td>0.047149</td>\n",
       "      <td>0.983187</td>\n",
       "      <td>-52.865107</td>\n",
       "      <td>9.246680</td>\n",
       "      <td>0.185203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053265</td>\n",
       "      <td>0.168078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092555</td>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.550669</td>\n",
       "      <td>0.555094</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-83.192209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010063         0.904416  1.797813   \n",
       "1       2                  0.020026         0.882080  1.779286   \n",
       "2       3                  0.030090         0.868775  1.779653   \n",
       "3       4                  0.040052         0.855016  1.760943   \n",
       "4       5                  0.050015         0.844864  1.669227   \n",
       "5       6                  0.100030         0.801044  1.647894   \n",
       "6       7                  0.150045         0.766324  1.487124   \n",
       "7       8                  0.200060         0.734445  1.530971   \n",
       "8       9                  0.299990         0.679120  1.397183   \n",
       "9      10                  0.400020         0.628140  1.262411   \n",
       "10     11                  0.500050         0.577733  1.150968   \n",
       "11     12                  0.599980         0.525297  0.945476   \n",
       "12     13                  0.700010         0.467384  0.792889   \n",
       "13     14                  0.799940         0.387435  0.599838   \n",
       "14     15                  0.899970         0.248567  0.471349   \n",
       "15     16                  1.000000         0.053265  0.168078   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.797813       0.990000  0.918861                  0.990000   \n",
       "1          1.788596       0.979798  0.892798                  0.984925   \n",
       "2          1.785605       0.980000  0.875224                  0.983278   \n",
       "3          1.779470       0.969697  0.861853                  0.979899   \n",
       "4          1.757510       0.919192  0.849855                  0.967807   \n",
       "5          1.702702       0.907445  0.822436                  0.937626   \n",
       "6          1.630843       0.818913  0.782763                  0.898055   \n",
       "7          1.605875       0.843058  0.750382                  0.884306   \n",
       "8          1.536358       0.769386  0.705591                  0.846025   \n",
       "9          1.467854       0.695171  0.653904                  0.808302   \n",
       "10         1.404464       0.633803  0.603491                  0.773395   \n",
       "11         1.328017       0.520645  0.551709                  0.731298   \n",
       "12         1.251548       0.436620  0.497791                  0.689189   \n",
       "13         1.170136       0.330312  0.429691                  0.644358   \n",
       "14         1.092467       0.259557  0.324762                  0.601588   \n",
       "15         1.000000       0.092555  0.166339                  0.550669   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           0.918861      0.018092                 0.018092  79.781250   \n",
       "1           0.905895      0.017727                 0.035819  77.928591   \n",
       "2           0.895637      0.017909                 0.053728  77.965278   \n",
       "3           0.887233      0.017544                 0.071272  76.094276   \n",
       "4           0.879788      0.016630                 0.087902  66.922699   \n",
       "5           0.851112      0.082420                 0.170322  64.789431   \n",
       "6           0.828329      0.074379                 0.244700  48.712413   \n",
       "7           0.808842      0.076572                 0.321272  53.097055   \n",
       "8           0.774448      0.139620                 0.460892  39.718306   \n",
       "9           0.744304      0.126279                 0.587171  26.241127   \n",
       "10          0.716136      0.115132                 0.702303  15.096831   \n",
       "11          0.688750      0.094481                 0.796784  -5.452403   \n",
       "12          0.661462      0.079313                 0.876096 -20.711072   \n",
       "13          0.632509      0.059942                 0.936038 -40.016225   \n",
       "14          0.598303      0.047149                 0.983187 -52.865107   \n",
       "15          0.555094      0.016813                 1.000000 -83.192209   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0         79.781250            0.017868  \n",
       "1         78.859576            0.035147  \n",
       "2         78.560479            0.052608  \n",
       "3         77.947027            0.069480  \n",
       "4         75.751034            0.084319  \n",
       "5         70.270233            0.156436  \n",
       "6         63.084293            0.210658  \n",
       "7         60.587483            0.269760  \n",
       "8         53.635758            0.358092  \n",
       "9         46.785377            0.416510  \n",
       "10        40.446393            0.450119  \n",
       "11        32.801726            0.437993  \n",
       "12        25.154842            0.391886  \n",
       "13        17.013583            0.302891  \n",
       "14         9.246680            0.185203  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.20820677701655707\n",
      "RMSE: 0.4562968080280171\n",
      "LogLoss: 0.603231647498935\n",
      "Null degrees of freedom: 404536\n",
      "Residual degrees of freedom: 404520\n",
      "Null deviance: 555998.6216986472\n",
      "Residual deviance: 488059.0419685533\n",
      "AIC: 488093.0419685533\n",
      "AUC: 0.7252667132070488\n",
      "AUCPR: 0.748255713736204\n",
      "Gini: 0.45053342641409766\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.38174915560566514: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59038.0</td>\n",
       "      <td>121197.0</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>(121197.0/180235.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18712.0</td>\n",
       "      <td>205590.0</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>(18712.0/224302.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>77750.0</td>\n",
       "      <td>326787.0</td>\n",
       "      <td>0.3458</td>\n",
       "      <td>(139909.0/404537.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1   Error                  Rate\n",
       "0      0  59038.0  121197.0  0.6724   (121197.0/180235.0)\n",
       "1      1  18712.0  205590.0  0.0834    (18712.0/224302.0)\n",
       "2  Total  77750.0  326787.0  0.3458   (139909.0/404537.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.381749</td>\n",
       "      <td>0.746123</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.179475</td>\n",
       "      <td>0.865849</td>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.700174</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.502410</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.949927</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.949927</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.502410</td>\n",
       "      <td>0.328340</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.570839</td>\n",
       "      <td>0.661398</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.663370</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.949927</td>\n",
       "      <td>180233.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.949927</td>\n",
       "      <td>224269.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>180235.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>224302.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.949927</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.949927</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold          value    idx\n",
       "0                        max f1   0.381749       0.746123  277.0\n",
       "1                        max f2   0.179475       0.865849  358.0\n",
       "2                  max f0point5   0.559633       0.700174  183.0\n",
       "3                  max accuracy   0.502410       0.672000  216.0\n",
       "4                 max precision   0.949927       0.942857    0.0\n",
       "5                    max recall   0.052612       1.000000  399.0\n",
       "6               max specificity   0.949927       0.999989    0.0\n",
       "7              max absolute_mcc   0.502410       0.328340  216.0\n",
       "8    max min_per_class_accuracy   0.570839       0.661398  177.0\n",
       "9   max mean_per_class_accuracy   0.559633       0.663370  183.0\n",
       "10                      max tns   0.949927  180233.000000    0.0\n",
       "11                      max fns   0.949927  224269.000000    0.0\n",
       "12                      max fps   0.052612  180235.000000  399.0\n",
       "13                      max tps   0.052612  224302.000000  399.0\n",
       "14                      max tnr   0.949927       0.999989    0.0\n",
       "15                      max fnr   0.949927       0.999853    0.0\n",
       "16                      max fpr   0.052612       1.000000  399.0\n",
       "17                      max tpr   0.052612       1.000000  399.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 55.45 %, avg score: 55.45 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.896733</td>\n",
       "      <td>1.659557</td>\n",
       "      <td>1.659557</td>\n",
       "      <td>0.920168</td>\n",
       "      <td>0.913436</td>\n",
       "      <td>0.920168</td>\n",
       "      <td>0.913436</td>\n",
       "      <td>0.016598</td>\n",
       "      <td>0.016598</td>\n",
       "      <td>65.955734</td>\n",
       "      <td>65.955734</td>\n",
       "      <td>0.014806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>0.876846</td>\n",
       "      <td>1.600221</td>\n",
       "      <td>1.629893</td>\n",
       "      <td>0.887268</td>\n",
       "      <td>0.886112</td>\n",
       "      <td>0.903720</td>\n",
       "      <td>0.899775</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.032599</td>\n",
       "      <td>60.022126</td>\n",
       "      <td>62.989296</td>\n",
       "      <td>0.028277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030002</td>\n",
       "      <td>0.861619</td>\n",
       "      <td>1.558816</td>\n",
       "      <td>1.606199</td>\n",
       "      <td>0.864310</td>\n",
       "      <td>0.868802</td>\n",
       "      <td>0.890583</td>\n",
       "      <td>0.889450</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>0.048189</td>\n",
       "      <td>55.881601</td>\n",
       "      <td>60.619869</td>\n",
       "      <td>0.040821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.849365</td>\n",
       "      <td>1.529328</td>\n",
       "      <td>1.586983</td>\n",
       "      <td>0.847960</td>\n",
       "      <td>0.855462</td>\n",
       "      <td>0.879928</td>\n",
       "      <td>0.880954</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.063481</td>\n",
       "      <td>52.932820</td>\n",
       "      <td>58.698345</td>\n",
       "      <td>0.052701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.838343</td>\n",
       "      <td>1.511493</td>\n",
       "      <td>1.571887</td>\n",
       "      <td>0.838072</td>\n",
       "      <td>0.843782</td>\n",
       "      <td>0.871558</td>\n",
       "      <td>0.873520</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.078595</td>\n",
       "      <td>51.149347</td>\n",
       "      <td>57.188694</td>\n",
       "      <td>0.064180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>0.796370</td>\n",
       "      <td>1.463819</td>\n",
       "      <td>1.517853</td>\n",
       "      <td>0.811638</td>\n",
       "      <td>0.816251</td>\n",
       "      <td>0.841598</td>\n",
       "      <td>0.844886</td>\n",
       "      <td>0.073192</td>\n",
       "      <td>0.151786</td>\n",
       "      <td>46.381916</td>\n",
       "      <td>51.785305</td>\n",
       "      <td>0.116233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150001</td>\n",
       "      <td>0.761342</td>\n",
       "      <td>1.398016</td>\n",
       "      <td>1.477907</td>\n",
       "      <td>0.775152</td>\n",
       "      <td>0.778404</td>\n",
       "      <td>0.819449</td>\n",
       "      <td>0.822725</td>\n",
       "      <td>0.069901</td>\n",
       "      <td>0.221688</td>\n",
       "      <td>39.801551</td>\n",
       "      <td>47.790720</td>\n",
       "      <td>0.160900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.730510</td>\n",
       "      <td>1.331677</td>\n",
       "      <td>1.441350</td>\n",
       "      <td>0.738370</td>\n",
       "      <td>0.745601</td>\n",
       "      <td>0.799179</td>\n",
       "      <td>0.803444</td>\n",
       "      <td>0.066584</td>\n",
       "      <td>0.288272</td>\n",
       "      <td>33.167687</td>\n",
       "      <td>44.134962</td>\n",
       "      <td>0.198123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.676406</td>\n",
       "      <td>1.262070</td>\n",
       "      <td>1.381591</td>\n",
       "      <td>0.699775</td>\n",
       "      <td>0.702712</td>\n",
       "      <td>0.766045</td>\n",
       "      <td>0.769867</td>\n",
       "      <td>0.126205</td>\n",
       "      <td>0.414477</td>\n",
       "      <td>26.207033</td>\n",
       "      <td>38.159084</td>\n",
       "      <td>0.256944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.627133</td>\n",
       "      <td>1.190217</td>\n",
       "      <td>1.333747</td>\n",
       "      <td>0.659935</td>\n",
       "      <td>0.651396</td>\n",
       "      <td>0.739517</td>\n",
       "      <td>0.740249</td>\n",
       "      <td>0.119023</td>\n",
       "      <td>0.533499</td>\n",
       "      <td>19.021685</td>\n",
       "      <td>33.374705</td>\n",
       "      <td>0.299638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.579044</td>\n",
       "      <td>1.103415</td>\n",
       "      <td>1.287680</td>\n",
       "      <td>0.611806</td>\n",
       "      <td>0.603226</td>\n",
       "      <td>0.713975</td>\n",
       "      <td>0.712844</td>\n",
       "      <td>0.110342</td>\n",
       "      <td>0.643842</td>\n",
       "      <td>10.341488</td>\n",
       "      <td>28.768039</td>\n",
       "      <td>0.322850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.527975</td>\n",
       "      <td>1.002550</td>\n",
       "      <td>1.240159</td>\n",
       "      <td>0.555880</td>\n",
       "      <td>0.553865</td>\n",
       "      <td>0.687626</td>\n",
       "      <td>0.686348</td>\n",
       "      <td>0.100253</td>\n",
       "      <td>0.744095</td>\n",
       "      <td>0.254965</td>\n",
       "      <td>24.015938</td>\n",
       "      <td>0.323422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.469080</td>\n",
       "      <td>0.895973</td>\n",
       "      <td>1.190990</td>\n",
       "      <td>0.496786</td>\n",
       "      <td>0.499579</td>\n",
       "      <td>0.660363</td>\n",
       "      <td>0.659667</td>\n",
       "      <td>0.089598</td>\n",
       "      <td>0.833693</td>\n",
       "      <td>-10.402712</td>\n",
       "      <td>19.098953</td>\n",
       "      <td>0.300073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.388934</td>\n",
       "      <td>0.774728</td>\n",
       "      <td>1.138958</td>\n",
       "      <td>0.429560</td>\n",
       "      <td>0.431965</td>\n",
       "      <td>0.631513</td>\n",
       "      <td>0.631204</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>0.911164</td>\n",
       "      <td>-22.527215</td>\n",
       "      <td>13.895763</td>\n",
       "      <td>0.249512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899999</td>\n",
       "      <td>0.250889</td>\n",
       "      <td>0.590851</td>\n",
       "      <td>1.078056</td>\n",
       "      <td>0.327607</td>\n",
       "      <td>0.326243</td>\n",
       "      <td>0.597746</td>\n",
       "      <td>0.597320</td>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.970250</td>\n",
       "      <td>-40.914920</td>\n",
       "      <td>7.805637</td>\n",
       "      <td>0.157677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041387</td>\n",
       "      <td>0.297498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164953</td>\n",
       "      <td>0.168738</td>\n",
       "      <td>0.554466</td>\n",
       "      <td>0.554461</td>\n",
       "      <td>0.029750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-70.250152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010002         0.896733  1.659557   \n",
       "1       2                  0.020001         0.876846  1.600221   \n",
       "2       3                  0.030002         0.861619  1.558816   \n",
       "3       4                  0.040001         0.849365  1.529328   \n",
       "4       5                  0.050000         0.838343  1.511493   \n",
       "5       6                  0.100001         0.796370  1.463819   \n",
       "6       7                  0.150001         0.761342  1.398016   \n",
       "7       8                  0.200001         0.730510  1.331677   \n",
       "8       9                  0.300000         0.676406  1.262070   \n",
       "9      10                  0.400000         0.627133  1.190217   \n",
       "10     11                  0.500001         0.579044  1.103415   \n",
       "11     12                  0.600000         0.527975  1.002550   \n",
       "12     13                  0.700000         0.469080  0.895973   \n",
       "13     14                  0.799999         0.388934  0.774728   \n",
       "14     15                  0.899999         0.250889  0.590851   \n",
       "15     16                  1.000000         0.041387  0.297498   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.659557       0.920168  0.913436                  0.920168   \n",
       "1          1.629893       0.887268  0.886112                  0.903720   \n",
       "2          1.606199       0.864310  0.868802                  0.890583   \n",
       "3          1.586983       0.847960  0.855462                  0.879928   \n",
       "4          1.571887       0.838072  0.843782                  0.871558   \n",
       "5          1.517853       0.811638  0.816251                  0.841598   \n",
       "6          1.477907       0.775152  0.778404                  0.819449   \n",
       "7          1.441350       0.738370  0.745601                  0.799179   \n",
       "8          1.381591       0.699775  0.702712                  0.766045   \n",
       "9          1.333747       0.659935  0.651396                  0.739517   \n",
       "10         1.287680       0.611806  0.603226                  0.713975   \n",
       "11         1.240159       0.555880  0.553865                  0.687626   \n",
       "12         1.190990       0.496786  0.499579                  0.660363   \n",
       "13         1.138958       0.429560  0.431965                  0.631513   \n",
       "14         1.078056       0.327607  0.326243                  0.597746   \n",
       "15         1.000000       0.164953  0.168738                  0.554466   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           0.913436      0.016598                 0.016598  65.955734   \n",
       "1           0.899775      0.016001                 0.032599  60.022126   \n",
       "2           0.889450      0.015591                 0.048189  55.881601   \n",
       "3           0.880954      0.015292                 0.063481  52.932820   \n",
       "4           0.873520      0.015114                 0.078595  51.149347   \n",
       "5           0.844886      0.073192                 0.151786  46.381916   \n",
       "6           0.822725      0.069901                 0.221688  39.801551   \n",
       "7           0.803444      0.066584                 0.288272  33.167687   \n",
       "8           0.769867      0.126205                 0.414477  26.207033   \n",
       "9           0.740249      0.119023                 0.533499  19.021685   \n",
       "10          0.712844      0.110342                 0.643842  10.341488   \n",
       "11          0.686348      0.100253                 0.744095   0.254965   \n",
       "12          0.659667      0.089598                 0.833693 -10.402712   \n",
       "13          0.631204      0.077471                 0.911164 -22.527215   \n",
       "14          0.597320      0.059086                 0.970250 -40.914920   \n",
       "15          0.554461      0.029750                 1.000000 -70.250152   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0         65.955734            0.014806  \n",
       "1         62.989296            0.028277  \n",
       "2         60.619869            0.040821  \n",
       "3         58.698345            0.052701  \n",
       "4         57.188694            0.064180  \n",
       "5         51.785305            0.116233  \n",
       "6         47.790720            0.160900  \n",
       "7         44.134962            0.198123  \n",
       "8         38.159084            0.256944  \n",
       "9         33.374705            0.299638  \n",
       "10        28.768039            0.322850  \n",
       "11        24.015938            0.323422  \n",
       "12        19.098953            0.300073  \n",
       "13        13.895763            0.249512  \n",
       "14         7.805637            0.157677  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.653318</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.653063</td>\n",
       "      <td>0.652119</td>\n",
       "      <td>0.653981</td>\n",
       "      <td>0.656031</td>\n",
       "      <td>0.651397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.725800</td>\n",
       "      <td>0.720918</td>\n",
       "      <td>0.726584</td>\n",
       "      <td>0.726905</td>\n",
       "      <td>0.726169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>err</td>\n",
       "      <td>0.346682</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.346937</td>\n",
       "      <td>0.347880</td>\n",
       "      <td>0.346019</td>\n",
       "      <td>0.343969</td>\n",
       "      <td>0.348603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err_count</td>\n",
       "      <td>28049.000000</td>\n",
       "      <td>124.893950</td>\n",
       "      <td>28096.000000</td>\n",
       "      <td>28091.000000</td>\n",
       "      <td>27949.000000</td>\n",
       "      <td>27899.000000</td>\n",
       "      <td>28210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f0point5</td>\n",
       "      <td>0.670473</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.670696</td>\n",
       "      <td>0.669324</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.673216</td>\n",
       "      <td>0.668375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.746323</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.747170</td>\n",
       "      <td>0.744234</td>\n",
       "      <td>0.746207</td>\n",
       "      <td>0.747436</td>\n",
       "      <td>0.746568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f2</td>\n",
       "      <td>0.841534</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.843328</td>\n",
       "      <td>0.838025</td>\n",
       "      <td>0.840789</td>\n",
       "      <td>0.840048</td>\n",
       "      <td>0.845481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lift_top_group</td>\n",
       "      <td>1.660948</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>1.659504</td>\n",
       "      <td>1.657710</td>\n",
       "      <td>1.657954</td>\n",
       "      <td>1.672812</td>\n",
       "      <td>1.656758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.603234</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.602313</td>\n",
       "      <td>0.606900</td>\n",
       "      <td>0.602418</td>\n",
       "      <td>0.601946</td>\n",
       "      <td>0.602591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.678272</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>0.683927</td>\n",
       "      <td>0.673254</td>\n",
       "      <td>0.674308</td>\n",
       "      <td>0.668906</td>\n",
       "      <td>0.690966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.307372</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.306215</td>\n",
       "      <td>0.304358</td>\n",
       "      <td>0.308974</td>\n",
       "      <td>0.310139</td>\n",
       "      <td>0.307173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.620748</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.619273</td>\n",
       "      <td>0.620818</td>\n",
       "      <td>0.622043</td>\n",
       "      <td>0.623391</td>\n",
       "      <td>0.618214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.379252</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.380727</td>\n",
       "      <td>0.379182</td>\n",
       "      <td>0.377957</td>\n",
       "      <td>0.376608</td>\n",
       "      <td>0.381786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.208208</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.207853</td>\n",
       "      <td>0.209779</td>\n",
       "      <td>0.207838</td>\n",
       "      <td>0.207632</td>\n",
       "      <td>0.207936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>null_deviance</td>\n",
       "      <td>111199.730000</td>\n",
       "      <td>169.930000</td>\n",
       "      <td>111259.220000</td>\n",
       "      <td>111026.080000</td>\n",
       "      <td>111035.350000</td>\n",
       "      <td>111428.450000</td>\n",
       "      <td>111249.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pr_auc</td>\n",
       "      <td>0.748271</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.750007</td>\n",
       "      <td>0.743111</td>\n",
       "      <td>0.748810</td>\n",
       "      <td>0.751823</td>\n",
       "      <td>0.747606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.627930</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.627855</td>\n",
       "      <td>0.627235</td>\n",
       "      <td>0.628391</td>\n",
       "      <td>0.631416</td>\n",
       "      <td>0.624752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.157166</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.158131</td>\n",
       "      <td>0.151269</td>\n",
       "      <td>0.158877</td>\n",
       "      <td>0.158985</td>\n",
       "      <td>0.158565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.919768</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.922474</td>\n",
       "      <td>0.914891</td>\n",
       "      <td>0.918393</td>\n",
       "      <td>0.915689</td>\n",
       "      <td>0.927395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>residual_deviance</td>\n",
       "      <td>97611.805000</td>\n",
       "      <td>254.487660</td>\n",
       "      <td>97554.266000</td>\n",
       "      <td>98013.220000</td>\n",
       "      <td>97318.180000</td>\n",
       "      <td>97646.414000</td>\n",
       "      <td>97526.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean          sd     cv_1_valid  \\\n",
       "0                  accuracy       0.653318    0.001802       0.653063   \n",
       "1                       auc       0.725275    0.002471       0.725800   \n",
       "2                       err       0.346682    0.001802       0.346937   \n",
       "3                 err_count   28049.000000  124.893950   28096.000000   \n",
       "4                  f0point5       0.670473    0.001828       0.670696   \n",
       "5                        f1       0.746323    0.001264       0.747170   \n",
       "6                        f2       0.841534    0.002910       0.843328   \n",
       "7            lift_top_group       1.660948    0.006705       1.659504   \n",
       "8                   logloss       0.603234    0.002063       0.602313   \n",
       "9       max_per_class_error       0.678272    0.008968       0.683927   \n",
       "10                      mcc       0.307372    0.002274       0.306215   \n",
       "11  mean_per_class_accuracy       0.620748    0.002077       0.619273   \n",
       "12     mean_per_class_error       0.379252    0.002077       0.380727   \n",
       "13                      mse       0.208208    0.000885       0.207853   \n",
       "14            null_deviance  111199.730000  169.930000  111259.220000   \n",
       "15                   pr_auc       0.748271    0.003278       0.750007   \n",
       "16                precision       0.627930    0.002396       0.627855   \n",
       "17                       r2       0.157166    0.003313       0.158131   \n",
       "18                   recall       0.919768    0.005191       0.922474   \n",
       "19        residual_deviance   97611.805000  254.487660   97554.266000   \n",
       "\n",
       "       cv_2_valid     cv_3_valid     cv_4_valid     cv_5_valid  \n",
       "0        0.652119       0.653981       0.656031       0.651397  \n",
       "1        0.720918       0.726584       0.726905       0.726169  \n",
       "2        0.347880       0.346019       0.343969       0.348603  \n",
       "3    28091.000000   27949.000000   27899.000000   28210.000000  \n",
       "4        0.669324       0.670752       0.673216       0.668375  \n",
       "5        0.744234       0.746207       0.747436       0.746568  \n",
       "6        0.838025       0.840789       0.840048       0.845481  \n",
       "7        1.657710       1.657954       1.672812       1.656758  \n",
       "8        0.606900       0.602418       0.601946       0.602591  \n",
       "9        0.673254       0.674308       0.668906       0.690966  \n",
       "10       0.304358       0.308974       0.310139       0.307173  \n",
       "11       0.620818       0.622043       0.623391       0.618214  \n",
       "12       0.379182       0.377957       0.376608       0.381786  \n",
       "13       0.209779       0.207838       0.207632       0.207936  \n",
       "14  111026.080000  111035.350000  111428.450000  111249.520000  \n",
       "15       0.743111       0.748810       0.751823       0.747606  \n",
       "16       0.627235       0.628391       0.631416       0.624752  \n",
       "17       0.151269       0.158877       0.158985       0.158565  \n",
       "18       0.914891       0.918393       0.915689       0.927395  \n",
       "19   98013.220000   97318.180000   97646.414000   97526.960000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml = H2OAutoML(max_runtime_secs = 3600)\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "# train = h2o.H2OFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T2g-N1P-TSmz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                               </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_1_20220501_153607   </td><td style=\"text-align: right;\">0.725267</td><td style=\"text-align: right;\"> 0.603232</td><td style=\"text-align: right;\">0.748256</td><td style=\"text-align: right;\">              0.377931</td><td style=\"text-align: right;\">0.456297</td><td style=\"text-align: right;\">0.208207</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_4_AutoML_1_20220501_153607   </td><td style=\"text-align: right;\">0.725254</td><td style=\"text-align: right;\"> 0.603243</td><td style=\"text-align: right;\">0.748221</td><td style=\"text-align: right;\">              0.380308</td><td style=\"text-align: right;\">0.456301</td><td style=\"text-align: right;\">0.208211</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_2_AutoML_1_20220501_153607   </td><td style=\"text-align: right;\">0.723156</td><td style=\"text-align: right;\"> 0.604877</td><td style=\"text-align: right;\">0.746204</td><td style=\"text-align: right;\">              0.37879 </td><td style=\"text-align: right;\">0.457071</td><td style=\"text-align: right;\">0.208914</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20220501_153607   </td><td style=\"text-align: right;\">0.72306 </td><td style=\"text-align: right;\"> 0.60494 </td><td style=\"text-align: right;\">0.746065</td><td style=\"text-align: right;\">              0.380696</td><td style=\"text-align: right;\">0.457099</td><td style=\"text-align: right;\">0.208939</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_4_AutoML_1_20220501_153607</td><td style=\"text-align: right;\">0.722682</td><td style=\"text-align: right;\"> 0.605148</td><td style=\"text-align: right;\">0.745899</td><td style=\"text-align: right;\">              0.382598</td><td style=\"text-align: right;\">0.457214</td><td style=\"text-align: right;\">0.209045</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_3_AutoML_1_20220501_153607</td><td style=\"text-align: right;\">0.722306</td><td style=\"text-align: right;\"> 0.605521</td><td style=\"text-align: right;\">0.745275</td><td style=\"text-align: right;\">              0.384475</td><td style=\"text-align: right;\">0.45737 </td><td style=\"text-align: right;\">0.209187</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_1_20220501_153607</td><td style=\"text-align: right;\">0.722088</td><td style=\"text-align: right;\"> 0.605661</td><td style=\"text-align: right;\">0.745107</td><td style=\"text-align: right;\">              0.379756</td><td style=\"text-align: right;\">0.457439</td><td style=\"text-align: right;\">0.209251</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20220501_153607</td><td style=\"text-align: right;\">0.721769</td><td style=\"text-align: right;\"> 0.60587 </td><td style=\"text-align: right;\">0.744841</td><td style=\"text-align: right;\">              0.382111</td><td style=\"text-align: right;\">0.457539</td><td style=\"text-align: right;\">0.209342</td></tr>\n",
       "<tr><td>GBM_1_AutoML_1_20220501_153607                         </td><td style=\"text-align: right;\">0.720667</td><td style=\"text-align: right;\"> 0.606659</td><td style=\"text-align: right;\">0.743892</td><td style=\"text-align: right;\">              0.383203</td><td style=\"text-align: right;\">0.457918</td><td style=\"text-align: right;\">0.209689</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_9            </td><td style=\"text-align: right;\">0.719135</td><td style=\"text-align: right;\"> 0.608059</td><td style=\"text-align: right;\">0.742121</td><td style=\"text-align: right;\">              0.384779</td><td style=\"text-align: right;\">0.458556</td><td style=\"text-align: right;\">0.210274</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_4        </td><td style=\"text-align: right;\">0.718681</td><td style=\"text-align: right;\"> 0.608689</td><td style=\"text-align: right;\">0.742129</td><td style=\"text-align: right;\">              0.385593</td><td style=\"text-align: right;\">0.458847</td><td style=\"text-align: right;\">0.21054 </td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20220501_153607                         </td><td style=\"text-align: right;\">0.718118</td><td style=\"text-align: right;\"> 0.608513</td><td style=\"text-align: right;\">0.741296</td><td style=\"text-align: right;\">              0.386072</td><td style=\"text-align: right;\">0.4588  </td><td style=\"text-align: right;\">0.210497</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_3        </td><td style=\"text-align: right;\">0.717489</td><td style=\"text-align: right;\"> 0.609076</td><td style=\"text-align: right;\">0.740696</td><td style=\"text-align: right;\">              0.38707 </td><td style=\"text-align: right;\">0.459044</td><td style=\"text-align: right;\">0.210721</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_4            </td><td style=\"text-align: right;\">0.716996</td><td style=\"text-align: right;\"> 0.609193</td><td style=\"text-align: right;\">0.740493</td><td style=\"text-align: right;\">              0.382504</td><td style=\"text-align: right;\">0.45916 </td><td style=\"text-align: right;\">0.210828</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_6        </td><td style=\"text-align: right;\">0.716777</td><td style=\"text-align: right;\"> 0.609659</td><td style=\"text-align: right;\">0.739813</td><td style=\"text-align: right;\">              0.387564</td><td style=\"text-align: right;\">0.459292</td><td style=\"text-align: right;\">0.210949</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_8        </td><td style=\"text-align: right;\">0.715669</td><td style=\"text-align: right;\"> 0.610212</td><td style=\"text-align: right;\">0.738867</td><td style=\"text-align: right;\">              0.389364</td><td style=\"text-align: right;\">0.459579</td><td style=\"text-align: right;\">0.211213</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_7        </td><td style=\"text-align: right;\">0.715568</td><td style=\"text-align: right;\"> 0.612666</td><td style=\"text-align: right;\">0.738174</td><td style=\"text-align: right;\">              0.390603</td><td style=\"text-align: right;\">0.460495</td><td style=\"text-align: right;\">0.212056</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_2        </td><td style=\"text-align: right;\">0.714054</td><td style=\"text-align: right;\"> 0.613569</td><td style=\"text-align: right;\">0.736987</td><td style=\"text-align: right;\">              0.388492</td><td style=\"text-align: right;\">0.460874</td><td style=\"text-align: right;\">0.212405</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_1_20220501_153607                     </td><td style=\"text-align: right;\">0.713637</td><td style=\"text-align: right;\"> 0.612527</td><td style=\"text-align: right;\">0.735987</td><td style=\"text-align: right;\">              0.39404 </td><td style=\"text-align: right;\">0.460555</td><td style=\"text-align: right;\">0.212111</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_3            </td><td style=\"text-align: right;\">0.713616</td><td style=\"text-align: right;\"> 0.614539</td><td style=\"text-align: right;\">0.736251</td><td style=\"text-align: right;\">              0.392693</td><td style=\"text-align: right;\">0.461432</td><td style=\"text-align: right;\">0.212919</td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20220501_153607                         </td><td style=\"text-align: right;\">0.711702</td><td style=\"text-align: right;\"> 0.613074</td><td style=\"text-align: right;\">0.735515</td><td style=\"text-align: right;\">              0.39294 </td><td style=\"text-align: right;\">0.460976</td><td style=\"text-align: right;\">0.212499</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_10       </td><td style=\"text-align: right;\">0.711696</td><td style=\"text-align: right;\"> 0.612933</td><td style=\"text-align: right;\">0.735184</td><td style=\"text-align: right;\">              0.389299</td><td style=\"text-align: right;\">0.460896</td><td style=\"text-align: right;\">0.212425</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_1            </td><td style=\"text-align: right;\">0.710652</td><td style=\"text-align: right;\"> 0.614253</td><td style=\"text-align: right;\">0.734602</td><td style=\"text-align: right;\">              0.392938</td><td style=\"text-align: right;\">0.46147 </td><td style=\"text-align: right;\">0.212954</td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_1_20220501_153607                     </td><td style=\"text-align: right;\">0.709293</td><td style=\"text-align: right;\"> 0.619538</td><td style=\"text-align: right;\">0.732128</td><td style=\"text-align: right;\">              0.395221</td><td style=\"text-align: right;\">0.463435</td><td style=\"text-align: right;\">0.214772</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_2            </td><td style=\"text-align: right;\">0.708867</td><td style=\"text-align: right;\"> 0.615769</td><td style=\"text-align: right;\">0.732813</td><td style=\"text-align: right;\">              0.394067</td><td style=\"text-align: right;\">0.462221</td><td style=\"text-align: right;\">0.213648</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20220501_153607                         </td><td style=\"text-align: right;\">0.708867</td><td style=\"text-align: right;\"> 0.615025</td><td style=\"text-align: right;\">0.732516</td><td style=\"text-align: right;\">              0.391142</td><td style=\"text-align: right;\">0.461893</td><td style=\"text-align: right;\">0.213345</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_1        </td><td style=\"text-align: right;\">0.708789</td><td style=\"text-align: right;\"> 0.623409</td><td style=\"text-align: right;\">0.732438</td><td style=\"text-align: right;\">              0.399618</td><td style=\"text-align: right;\">0.464781</td><td style=\"text-align: right;\">0.216021</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_1_20220501_153607                     </td><td style=\"text-align: right;\">0.708586</td><td style=\"text-align: right;\"> 0.614925</td><td style=\"text-align: right;\">0.732421</td><td style=\"text-align: right;\">              0.389892</td><td style=\"text-align: right;\">0.461866</td><td style=\"text-align: right;\">0.21332 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_5        </td><td style=\"text-align: right;\">0.708195</td><td style=\"text-align: right;\"> 0.615168</td><td style=\"text-align: right;\">0.732062</td><td style=\"text-align: right;\">              0.393036</td><td style=\"text-align: right;\">0.461967</td><td style=\"text-align: right;\">0.213413</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_10           </td><td style=\"text-align: right;\">0.707561</td><td style=\"text-align: right;\"> 0.615957</td><td style=\"text-align: right;\">0.731385</td><td style=\"text-align: right;\">              0.392157</td><td style=\"text-align: right;\">0.462345</td><td style=\"text-align: right;\">0.213763</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_8            </td><td style=\"text-align: right;\">0.707175</td><td style=\"text-align: right;\"> 0.617221</td><td style=\"text-align: right;\">0.730541</td><td style=\"text-align: right;\">              0.390935</td><td style=\"text-align: right;\">0.462821</td><td style=\"text-align: right;\">0.214203</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_9        </td><td style=\"text-align: right;\">0.70678 </td><td style=\"text-align: right;\"> 0.624063</td><td style=\"text-align: right;\">0.729775</td><td style=\"text-align: right;\">              0.394425</td><td style=\"text-align: right;\">0.465126</td><td style=\"text-align: right;\">0.216342</td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20220501_153607                         </td><td style=\"text-align: right;\">0.706485</td><td style=\"text-align: right;\"> 0.620066</td><td style=\"text-align: right;\">0.72922 </td><td style=\"text-align: right;\">              0.396654</td><td style=\"text-align: right;\">0.463578</td><td style=\"text-align: right;\">0.214905</td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20220501_153607                         </td><td style=\"text-align: right;\">0.706159</td><td style=\"text-align: right;\"> 0.616823</td><td style=\"text-align: right;\">0.729868</td><td style=\"text-align: right;\">              0.392162</td><td style=\"text-align: right;\">0.462742</td><td style=\"text-align: right;\">0.21413 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_7            </td><td style=\"text-align: right;\">0.701193</td><td style=\"text-align: right;\"> 0.620032</td><td style=\"text-align: right;\">0.724821</td><td style=\"text-align: right;\">              0.398362</td><td style=\"text-align: right;\">0.464281</td><td style=\"text-align: right;\">0.215557</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20220501_153607                         </td><td style=\"text-align: right;\">0.699423</td><td style=\"text-align: right;\"> 0.630006</td><td style=\"text-align: right;\">0.723588</td><td style=\"text-align: right;\">              0.40446 </td><td style=\"text-align: right;\">0.467156</td><td style=\"text-align: right;\">0.218235</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_1_20220501_153607_model_11       </td><td style=\"text-align: right;\">0.697501</td><td style=\"text-align: right;\"> 0.622188</td><td style=\"text-align: right;\">0.721095</td><td style=\"text-align: right;\">              0.405187</td><td style=\"text-align: right;\">0.465324</td><td style=\"text-align: right;\">0.216527</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_12           </td><td style=\"text-align: right;\">0.69403 </td><td style=\"text-align: right;\"> 0.62502 </td><td style=\"text-align: right;\">0.717901</td><td style=\"text-align: right;\">              0.404165</td><td style=\"text-align: right;\">0.466652</td><td style=\"text-align: right;\">0.217764</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_5            </td><td style=\"text-align: right;\">0.693016</td><td style=\"text-align: right;\"> 0.625426</td><td style=\"text-align: right;\">0.717403</td><td style=\"text-align: right;\">              0.405901</td><td style=\"text-align: right;\">0.466818</td><td style=\"text-align: right;\">0.217919</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_13           </td><td style=\"text-align: right;\">0.687873</td><td style=\"text-align: right;\"> 0.652214</td><td style=\"text-align: right;\">0.710175</td><td style=\"text-align: right;\">              0.406311</td><td style=\"text-align: right;\">0.479438</td><td style=\"text-align: right;\">0.229861</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20220501_153607_model_11           </td><td style=\"text-align: right;\">0.686406</td><td style=\"text-align: right;\"> 0.630168</td><td style=\"text-align: right;\">0.709977</td><td style=\"text-align: right;\">              0.407448</td><td style=\"text-align: right;\">0.469019</td><td style=\"text-align: right;\">0.219979</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20220501_153607                </td><td style=\"text-align: right;\">0.663021</td><td style=\"text-align: right;\"> 0.639434</td><td style=\"text-align: right;\">0.68677 </td><td style=\"text-align: right;\">              0.416836</td><td style=\"text-align: right;\">0.47366 </td><td style=\"text-align: right;\">0.224353</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220501_153607_model_1   </td><td style=\"text-align: right;\">0.657662</td><td style=\"text-align: right;\"> 0.645082</td><td style=\"text-align: right;\">0.684602</td><td style=\"text-align: right;\">              0.417544</td><td style=\"text-align: right;\">0.476235</td><td style=\"text-align: right;\">0.2268  </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220501_153607_model_1   </td><td style=\"text-align: right;\">0.653475</td><td style=\"text-align: right;\"> 0.643518</td><td style=\"text-align: right;\">0.678678</td><td style=\"text-align: right;\">              0.417959</td><td style=\"text-align: right;\">0.475466</td><td style=\"text-align: right;\">0.226068</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220501_153607_model_2   </td><td style=\"text-align: right;\">0.651464</td><td style=\"text-align: right;\"> 0.646837</td><td style=\"text-align: right;\">0.677425</td><td style=\"text-align: right;\">              0.416704</td><td style=\"text-align: right;\">0.47713 </td><td style=\"text-align: right;\">0.227653</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220501_153607_model_3   </td><td style=\"text-align: right;\">0.648248</td><td style=\"text-align: right;\"> 0.647048</td><td style=\"text-align: right;\">0.676312</td><td style=\"text-align: right;\">              0.422866</td><td style=\"text-align: right;\">0.477318</td><td style=\"text-align: right;\">0.227832</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220501_153607_model_1   </td><td style=\"text-align: right;\">0.632277</td><td style=\"text-align: right;\"> 0.659839</td><td style=\"text-align: right;\">0.659645</td><td style=\"text-align: right;\">              0.422634</td><td style=\"text-align: right;\">0.483477</td><td style=\"text-align: right;\">0.23375 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20220501_153607_model_2   </td><td style=\"text-align: right;\">0.631103</td><td style=\"text-align: right;\"> 0.667113</td><td style=\"text-align: right;\">0.665565</td><td style=\"text-align: right;\">              0.446493</td><td style=\"text-align: right;\">0.486265</td><td style=\"text-align: right;\">0.236454</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20220501_153607                         </td><td style=\"text-align: right;\">0.605594</td><td style=\"text-align: right;\"> 0.670191</td><td style=\"text-align: right;\">0.638331</td><td style=\"text-align: right;\">              0.48702 </td><td style=\"text-align: right;\">0.488587</td><td style=\"text-align: right;\">0.238718</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20220501_153607_model_2   </td><td style=\"text-align: right;\">0.601871</td><td style=\"text-align: right;\"> 0.675423</td><td style=\"text-align: right;\">0.639691</td><td style=\"text-align: right;\">              0.488647</td><td style=\"text-align: right;\">0.49116 </td><td style=\"text-align: right;\">0.241238</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tm5_3CBwyetw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "H20AutoMLAirlines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "idlsvenv",
   "language": "python",
   "name": "idlsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
